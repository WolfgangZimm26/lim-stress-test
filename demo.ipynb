{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import json\n",
    "from itertools import combinations\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are trying to establish what could be going wrong with the docker container by breaking the functions in my module apart then testing them seperatly. After that we will test the fast api call and make sure no errors are still occuring. Finally the corret functions and api call will be put into a docker container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the environment variables from .env file\n",
    "#use the .env file to not expose our secret API key\n",
    "#load_dotenv()\n",
    "#client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "#    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv_path = os.path.join(os.path.dirname('lim-stress-tes'), '.env')\n",
    "load_dotenv(dotenv_path)\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first function is called get_openai_responses. It takes in a prompt and will obtain responses. The number of responses can be controlled by the num_responses. To limit the tokens set the varaible max_token. Initial_delay,exponetial_base are used when a rate limit occurs and it emplements exponetial backing. The function is set to retry 10 times if a rate limit error occurs. Adjust if need be\n",
    "\n",
    "***to test I set the num_responses = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_openai_responses(prompt, num_responses=40, max_tokens=100, initial_delay: float = 1,\n",
    "                         exponential_base: float = 2, jitter: bool = True):\n",
    "    \n",
    "    \"\"\"\n",
    "    Retrieves a specified number of responses from OpenAI's GPT model.\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): The prompt to send to the model.\n",
    "        num_responses (int): The number of responses to retrieve.\n",
    "        max_tokens (int): The maximum number of tokens per response.\n",
    "        initial_delay (float): Initial delay in seconds before retrying after a rate limit error.\n",
    "        exponential_base (float): The base for the exponential backoff calculation.\n",
    "        jitter (bool): Whether to add random jitter to the delay.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of responses from the AI model.\n",
    "    \"\"\"\n",
    "    if num_responses > 100:  # Example threshold\n",
    "        raise ValueError(\"num_responses is too high. Please reduce the number.\")\n",
    "\n",
    "    delay = initial_delay\n",
    "    responses = []\n",
    "    retries = 0\n",
    "    max_retries = 10\n",
    "\n",
    "    while len(responses) < num_responses and retries < max_retries:\n",
    "        try:\n",
    "            AI_response = client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant that provides recommendations.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt},\n",
    "                ],\n",
    "                max_tokens=max_tokens,\n",
    "                n=1,  # Number of completions to generate\n",
    "            )\n",
    "            #print(AI_response)\n",
    "            #need to eventually un comment these\n",
    "            response_content = AI_response.choices[0].message.content\n",
    "            responses.append(response_content)\n",
    "        except Exception as e:\n",
    "            print(f\"Encountered an error: {e}\")\n",
    "            if 'rate limit' in str(e).lower():\n",
    "                delay *= exponential_base * (1 + jitter * random.random())\n",
    "                print(f\"Rate limit exceeded. Waiting for {delay} seconds.\")\n",
    "                time.sleep(delay)\n",
    "            else:\n",
    "                print(\"Encountered a non-rate-limit error. Retrying...\")\n",
    "            retries += 1\n",
    "            time.sleep(initial_delay)  # Basic delay for non-rate-limit errors\n",
    "\n",
    "    if retries == max_retries:\n",
    "        print(\"Max retries reached. Some responses may not have been retrieved.\")\n",
    "\n",
    "    return responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next function is called get_bert_embedding. As the name states this function will obtain the bertembeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_embedding(my_text):\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    model = BertModel.from_pretrained('bert-base-uncased')\n",
    "    tokens = tokenizer(my_text, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**tokens)\n",
    "    last_hidden_states = outputs.last_hidden_state\n",
    "    embedding = torch.mean(last_hidden_states, dim=1)\n",
    "    \n",
    "    # Convert to numpy array and check shape\n",
    "    embedding_np = embedding.numpy()\n",
    "    #print(f\"Embedding shape: {embedding_np.shape}\")  # For debugging\n",
    "    return embedding_np.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last function in my module is process_prompt. This function will compare the cosine similarities for each response and compare each response to everyother response created. It will then return the quant scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DO Not USE\n",
    "\n",
    "def process_prompt(prompt):\n",
    "    result_data = []  # Store quant scores for all prompts\n",
    "    responses = get_openai_responses(prompt)\n",
    "\n",
    "    prompt_embedding = get_bert_embedding(prompt)\n",
    "    response_embeddings = [get_bert_embedding(response) for response in responses]\n",
    "\n",
    "    cosine_sim_scores = []\n",
    "    embedding_pairs = list(combinations([prompt_embedding] + response_embeddings, 2))\n",
    "    for pair in embedding_pairs:\n",
    "        score = cosine_similarity([pair[0]], [pair[1]])[0][0]\n",
    "        cosine_sim_scores.append(score)\n",
    "\n",
    "    mean_score = np.mean(cosine_sim_scores)\n",
    "    median_score = np.median(cosine_sim_scores)\n",
    "    mode_score = stats.mode(cosine_sim_scores)\n",
    "    average_score = np.average(cosine_sim_scores)\n",
    "    sample_size = len(cosine_sim_scores)\n",
    "\n",
    "    quant_scores = {\n",
    "        \"mean\": mean_score,\n",
    "        \"median\": median_score,\n",
    "        \"mode\": mode_score,\n",
    "        \"average\": average_score,\n",
    "        \"sample_size\": sample_size\n",
    "    }\n",
    "\n",
    "    result_data.append({\"prompt\": prompt, \"quant_scores\": quant_scores})\n",
    "\n",
    "    return result_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#original DO NOT USE\n",
    "\n",
    "def process_prompt(prompt):\n",
    "    result_data = []  # Store quant scores for all prompts\n",
    "    responses = get_openai_responses(prompt, num_responses=5)\n",
    "\n",
    "    prompt_embedding = get_bert_embedding(prompt)\n",
    "    response_embeddings = [get_bert_embedding(response) for response in responses]\n",
    "\n",
    "    cosine_sim_scores = []\n",
    "    for response_emb in response_embeddings:\n",
    "        # Compute cosine similarity between prompt and each response\n",
    "        # Since both are 2D arrays, no need to wrap them in another list\n",
    "        score = cosine_similarity(prompt_embedding, response_emb)[0][0]\n",
    "        cosine_sim_scores.append(score)\n",
    "    mean_score = np.mean(cosine_sim_scores)\n",
    "    median_score = np.median(cosine_sim_scores)\n",
    "    mode_result=stats.mode(cosine_sim_scores)\n",
    "    mode_score = mode_result.mode[0]\n",
    "    average_score = np.average(cosine_sim_scores)\n",
    "    sample_size = len(cosine_sim_scores)\n",
    "\n",
    "    quant_scores = {\n",
    "        \"mean\": mean_score,\n",
    "        \"median\": median_score,\n",
    "        \"mode\": mode_score,\n",
    "        \"average\": average_score,\n",
    "        \"sample_size\": sample_size\n",
    "    }\n",
    "\n",
    "    result_data.append({\"prompt\": prompt, \"quant_scores\": quant_scores})\n",
    "    return result_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#updated and unbugged\n",
    "\n",
    "def process_prompt(prompt):\n",
    "    result_data = []  # Store quant scores for all prompts\n",
    "    responses = get_openai_responses(prompt)\n",
    "\n",
    "    prompt_embedding = get_bert_embedding(prompt)  # This returns a list of lists\n",
    "    response_embeddings = [get_bert_embedding(response) for response in responses]\n",
    "\n",
    "    cosine_sim_scores = []\n",
    "    # Create combinations of the prompt embedding and all response embeddings\n",
    "    embedding_pairs = list(combinations([prompt_embedding] + response_embeddings, 2))\n",
    "    for pair in embedding_pairs:\n",
    "        # Since the embeddings are lists, they can be directly used\n",
    "        score = cosine_similarity([pair[0][0]], [pair[1][0]])[0][0]\n",
    "        cosine_sim_scores.append(score)\n",
    "\n",
    "        # Calculate statistical measures\n",
    "        mean_score = np.mean(cosine_sim_scores)\n",
    "        median_score = np.median(cosine_sim_scores)\n",
    "        mode_result = stats.mode(cosine_sim_scores, keepdims=False)\n",
    "\n",
    "\n",
    "        # Check if the mode result is a scalar or an array and extract the mode value\n",
    "        if np.isscalar(mode_result.mode):\n",
    "            mode_score = mode_result.mode\n",
    "        else:\n",
    "            mode_score = mode_result.mode[0] if mode_result.mode.size else None\n",
    "        average_score = np.average(cosine_sim_scores)\n",
    "        sample_size = len(cosine_sim_scores)\n",
    "\n",
    "        quant_scores = {\n",
    "            \"mean\": mean_score,\n",
    "            \"median\": median_score,\n",
    "            \"mode\": mode_score,\n",
    "            \"average\": average_score,\n",
    "            \"sample_size\": sample_size\n",
    "        }\n",
    "\n",
    "        result_data.append({\"prompt\": prompt, \"quant_scores\": quant_scores})\n",
    "\n",
    "    return result_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will test if we can get replies from the three functions in the module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Cell For get_openai_responses\n",
    "my_prompt='What is today?'\n",
    "my_results=get_openai_responses(my_prompt, num_responses=5)\n",
    "print(my_prompt)\n",
    "print(my_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test for berkembeding function:\n",
    "my_result2=get_bert_embedding(my_results[0])\n",
    "print(my_result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is today?\n",
      "[{'prompt': 'What is today?', 'quant_scores': {'mean': 0.724286940667646, 'median': 0.724286940667646, 'mode': 0.724286940667646, 'average': 0.724286940667646, 'sample_size': 1}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7189585978845091, 'median': 0.7189585978845091, 'mode': 0.7136302551013722, 'average': 0.7189585978845091, 'sample_size': 2}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.6847100118650652, 'median': 0.7136302551013722, 'mode': 0.6162128398261774, 'average': 0.6847100118650652, 'sample_size': 3}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.6252831393121462, 'median': 0.6649215474637749, 'mode': 0.44700252165338916, 'average': 0.6252831393121462, 'sample_size': 4}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.6434774106252421, 'median': 0.7136302551013722, 'mode': 0.44700252165338916, 'average': 0.6434774106252421, 'sample_size': 5}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.636637906386038, 'median': 0.6649215474637749, 'mode': 0.44700252165338916, 'average': 0.636637906386038, 'sample_size': 6}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.6295611943523849, 'median': 0.6162128398261774, 'mode': 0.44700252165338916, 'average': 0.6295611943523849, 'sample_size': 7}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.6403978570430402, 'median': 0.6649215474637749, 'mode': 0.716254495877626, 'average': 0.6403978570430402, 'sample_size': 8}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.6497188663346631, 'median': 0.7136302551013722, 'mode': 0.716254495877626, 'average': 0.6497188663346631, 'sample_size': 9}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.6438153029174746, 'median': 0.6649215474637749, 'mode': 0.716254495877626, 'average': 0.6438153029174746, 'sample_size': 10}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.6511309063493084, 'median': 0.7136302551013722, 'mode': 0.724286940667646, 'average': 0.6511309063493084, 'sample_size': 11}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.6474817030227692, 'median': 0.6649215474637749, 'mode': 0.724286940667646, 'average': 0.6474817030227692, 'sample_size': 12}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.6472057935595317, 'median': 0.643894880000681, 'mode': 0.724286940667646, 'average': 0.6472057935595317, 'sample_size': 13}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.6531701760484803, 'median': 0.6787625675510266, 'mode': 0.724286940667646, 'average': 0.6531701760484803, 'sample_size': 14}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.648685583678397, 'median': 0.643894880000681, 'mode': 0.724286940667646, 'average': 0.648685583678397, 'sample_size': 15}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.653410668490225, 'median': 0.6787625675510266, 'mode': 0.724286940667646, 'average': 0.653410668490225, 'sample_size': 16}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.6571073642188957, 'median': 0.7136302551013722, 'mode': 0.724286940667646, 'average': 0.6571073642188957, 'sample_size': 17}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.6602475248234777, 'median': 0.7136302551013722, 'mode': 0.724286940667646, 'average': 0.6602475248234777, 'sample_size': 18}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.6577310720783784, 'median': 0.7136302551013722, 'mode': 0.724286940667646, 'average': 0.6577310720783784, 'sample_size': 19}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.6603557751765183, 'median': 0.7119276945712751, 'mode': 0.724286940667646, 'average': 0.6603557751765183, 'sample_size': 20}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.6640190777130991, 'median': 0.7136302551013722, 'mode': 0.724286940667646, 'average': 0.6640190777130991, 'sample_size': 21}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.6613876155175581, 'median': 0.7119276945712751, 'mode': 0.724286940667646, 'average': 0.6613876155175581, 'sample_size': 22}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.6595666754695536, 'median': 0.7102251340411782, 'mode': 0.724286940667646, 'average': 0.6595666754695536, 'sample_size': 23}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.6618193246208793, 'median': 0.7119276945712751, 'mode': 0.724286940667646, 'average': 0.6618193246208793, 'sample_size': 24}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.6639967314711491, 'median': 0.7136302551013722, 'mode': 0.716254495877626, 'average': 0.6639967314711491, 'sample_size': 25}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.6659057131492345, 'median': 0.7136302551013722, 'mode': 0.7136302551013722, 'average': 0.6659057131492345, 'sample_size': 26}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.6675471731822695, 'median': 0.7136302551013722, 'mode': 0.7136302551013722, 'average': 0.6675471731822695, 'sample_size': 27}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.6691929975365232, 'median': 0.7136302551013722, 'mode': 0.7136302551013722, 'average': 0.6691929975365232, 'sample_size': 28}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.6668067792234993, 'median': 0.7136302551013722, 'mode': 0.7136302551013722, 'average': 0.6668067792234993, 'sample_size': 29}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.6592334549844929, 'median': 0.7119276945712751, 'mode': 0.7136302551013722, 'average': 0.6592334549844929, 'sample_size': 30}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.656942088710909, 'median': 0.7102251340411782, 'mode': 0.7136302551013722, 'average': 0.656942088710909, 'sample_size': 31}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.6559119539532612, 'median': 0.7102251340411782, 'mode': 0.7136302551013722, 'average': 0.6559119539532612, 'sample_size': 32}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.6532730762730989, 'median': 0.7102251340411782, 'mode': 0.7136302551013722, 'average': 0.6532730762730989, 'sample_size': 33}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.6553617193435268, 'median': 0.7102251340411782, 'mode': 0.7136302551013722, 'average': 0.6553617193435268, 'sample_size': 34}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.6570265346508938, 'median': 0.7102251340411782, 'mode': 0.7136302551013722, 'average': 0.6570265346508938, 'sample_size': 35}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.6586717557960807, 'median': 0.7119276945712751, 'mode': 0.7136302551013722, 'average': 0.6586717557960807, 'sample_size': 36}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.6600650903432456, 'median': 0.7102251340411782, 'mode': 0.7136302551013722, 'average': 0.6600650903432456, 'sample_size': 37}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.6615437589099397, 'median': 0.7119276945712751, 'mode': 0.7136302551013722, 'average': 0.6615437589099397, 'sample_size': 38}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.6627919992979202, 'median': 0.7102251340411782, 'mode': 0.7136302551013722, 'average': 0.6627919992979202, 'sample_size': 39}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.664128561712413, 'median': 0.7119276945712751, 'mode': 0.716254495877626, 'average': 0.664128561712413, 'sample_size': 40}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.6715145758335993, 'median': 0.7136302551013722, 'mode': 0.716254495877626, 'average': 0.6715145758335993, 'sample_size': 41}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.6742243549091729, 'median': 0.7136302551013722, 'mode': 0.716254495877626, 'average': 0.6742243549091729, 'sample_size': 42}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.6707069965416634, 'median': 0.7136302551013722, 'mode': 0.716254495877626, 'average': 0.6707069965416634, 'sample_size': 43}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.677192059836509, 'median': 0.7136302551013722, 'mode': 0.716254495877626, 'average': 0.677192059836509, 'sample_size': 44}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.6792915458583343, 'median': 0.7136302551013722, 'mode': 0.716254495877626, 'average': 0.6792915458583343, 'sample_size': 45}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.6810931433498162, 'median': 0.7136302551013722, 'mode': 0.716254495877626, 'average': 0.6810931433498162, 'sample_size': 46}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.6869432845873705, 'median': 0.7136302551013722, 'mode': 0.716254495877626, 'average': 0.6869432845873705, 'sample_size': 47}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.6934652994918004, 'median': 0.7136302551013722, 'mode': 0.716254495877626, 'average': 0.6934652994918004, 'sample_size': 48}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.6925121972888479, 'median': 0.7136302551013722, 'mode': 0.716254495877626, 'average': 0.6925121972888479, 'sample_size': 49}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.6986619533430709, 'median': 0.7136302551013722, 'mode': 0.716254495877626, 'average': 0.6986619533430709, 'sample_size': 50}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7003905892476264, 'median': 0.7136302551013722, 'mode': 0.716254495877626, 'average': 0.7003905892476264, 'sample_size': 51}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7027009331238923, 'median': 0.7136302551013722, 'mode': 0.716254495877626, 'average': 0.7027009331238923, 'sample_size': 52}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7068617450984621, 'median': 0.7136302551013722, 'mode': 0.716254495877626, 'average': 0.7068617450984621, 'sample_size': 53}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7062631079407824, 'median': 0.7136302551013722, 'mode': 0.716254495877626, 'average': 0.7062631079407824, 'sample_size': 54}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7116037787054955, 'median': 0.7136302551013722, 'mode': 0.716254495877626, 'average': 0.7116037787054955, 'sample_size': 55}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7159688858985201, 'median': 0.7136302551013722, 'mode': 0.716254495877626, 'average': 0.7159688858985201, 'sample_size': 56}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7203721535262839, 'median': 0.7136302551013722, 'mode': 0.716254495877626, 'average': 0.7203721535262839, 'sample_size': 57}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7212897254622878, 'median': 0.7149423754894991, 'mode': 0.716254495877626, 'average': 0.7212897254622878, 'sample_size': 58}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7254248455056959, 'median': 0.716254495877626, 'mode': 0.716254495877626, 'average': 0.7254248455056959, 'sample_size': 59}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7294650940441029, 'median': 0.716254495877626, 'mode': 0.716254495877626, 'average': 0.7294650940441029, 'sample_size': 60}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.730201534365236, 'median': 0.716254495877626, 'mode': 0.716254495877626, 'average': 0.730201534365236, 'sample_size': 61}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7300014742459316, 'median': 0.716254495877626, 'mode': 0.716254495877626, 'average': 0.7300014742459316, 'sample_size': 62}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7337626435544257, 'median': 0.716254495877626, 'mode': 0.716254495877626, 'average': 0.7337626435544257, 'sample_size': 63}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7372358800850576, 'median': 0.716254495877626, 'mode': 0.716254495877626, 'average': 0.7372358800850576, 'sample_size': 64}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7407700225557652, 'median': 0.716254495877626, 'mode': 0.716254495877626, 'average': 0.7407700225557652, 'sample_size': 65}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7441714132446683, 'median': 0.716254495877626, 'mode': 0.716254495877626, 'average': 0.7441714132446683, 'sample_size': 66}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7474965435049128, 'median': 0.716254495877626, 'mode': 0.716254495877626, 'average': 0.7474965435049128, 'sample_size': 67}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7472326257659087, 'median': 0.716254495877626, 'mode': 0.716254495877626, 'average': 0.7472326257659087, 'sample_size': 68}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7439640970362674, 'median': 0.716254495877626, 'mode': 0.716254495877626, 'average': 0.7439640970362674, 'sample_size': 69}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7432530623593993, 'median': 0.716254495877626, 'mode': 0.716254495877626, 'average': 0.7432530623593993, 'sample_size': 70}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7437658029964479, 'median': 0.716254495877626, 'mode': 0.716254495877626, 'average': 0.7437658029964479, 'sample_size': 71}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7424698876295456, 'median': 0.716254495877626, 'mode': 0.716254495877626, 'average': 0.7424698876295456, 'sample_size': 72}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.745997697388045, 'median': 0.716254495877626, 'mode': 0.716254495877626, 'average': 0.745997697388045, 'sample_size': 73}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7489836087838964, 'median': 0.716254495877626, 'mode': 0.716254495877626, 'average': 0.7489836087838964, 'sample_size': 74}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.751744491086976, 'median': 0.716254495877626, 'mode': 0.716254495877626, 'average': 0.751744491086976, 'sample_size': 75}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.754553929467718, 'median': 0.716254495877626, 'mode': 0.716254495877626, 'average': 0.754553929467718, 'sample_size': 76}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7571707587150838, 'median': 0.716254495877626, 'mode': 0.716254495877626, 'average': 0.7571707587150838, 'sample_size': 77}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7598385926805745, 'median': 0.7170261514229932, 'mode': 0.716254495877626, 'average': 0.7598385926805745, 'sample_size': 78}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7623222786151859, 'median': 0.7177978069683605, 'mode': 0.716254495877626, 'average': 0.7623222786151859, 'sample_size': 79}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7626027210466237, 'median': 0.7210423738180032, 'mode': 0.716254495877626, 'average': 0.7626027210466237, 'sample_size': 80}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7594495150960201, 'median': 0.7177978069683605, 'mode': 0.716254495877626, 'average': 0.7594495150960201, 'sample_size': 81}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7617849554213346, 'median': 0.7210423738180032, 'mode': 0.716254495877626, 'average': 0.7617849554213346, 'sample_size': 82}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7619986729424966, 'median': 0.724286940667646, 'mode': 0.716254495877626, 'average': 0.7619986729424966, 'sample_size': 83}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7619784251374442, 'median': 0.724286940667646, 'mode': 0.716254495877626, 'average': 0.7619784251374442, 'sample_size': 84}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7642016862743191, 'median': 0.724286940667646, 'mode': 0.716254495877626, 'average': 0.7642016862743191, 'sample_size': 85}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7665592845813741, 'median': 0.724286940667646, 'mode': 0.716254495877626, 'average': 0.7665592845813741, 'sample_size': 86}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7652565697737865, 'median': 0.724286940667646, 'mode': 0.716254495877626, 'average': 0.7652565697737865, 'sample_size': 87}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7675485989886416, 'median': 0.724286940667646, 'mode': 0.9669551406810538, 'average': 0.7675485989886416, 'sample_size': 88}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7677986927902695, 'median': 0.724286940667646, 'mode': 0.9669551406810538, 'average': 0.7677986927902695, 'sample_size': 89}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7685604169412326, 'median': 0.724286940667646, 'mode': 0.9669551406810538, 'average': 0.7685604169412326, 'sample_size': 90}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7702271396480177, 'median': 0.724286940667646, 'mode': 0.9669551406810538, 'average': 0.7702271396480177, 'sample_size': 91}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7691655727870154, 'median': 0.724286940667646, 'mode': 0.9669551406810538, 'average': 0.7691655727870154, 'sample_size': 92}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.771292342334263, 'median': 0.724286940667646, 'mode': 0.9669551406810538, 'average': 0.771292342334263, 'sample_size': 93}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7732036538176412, 'median': 0.724286940667646, 'mode': 0.9669551406810538, 'average': 0.7732036538176412, 'sample_size': 94}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7755909837774555, 'median': 0.724286940667646, 'mode': 0.9669551406810538, 'average': 0.7755909837774555, 'sample_size': 95}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7756061877440303, 'median': 0.7269185389601368, 'mode': 0.9669551406810538, 'average': 0.7756061877440303, 'sample_size': 96}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.777631786661389, 'median': 0.7295501372526276, 'mode': 0.9669551406810538, 'average': 0.777631786661389, 'sample_size': 97}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7796146732684013, 'median': 0.7301286428287198, 'mode': 0.9669551406810538, 'average': 0.7796146732684013, 'sample_size': 98}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7795481038205961, 'median': 0.730707148404812, 'mode': 0.9669551406810538, 'average': 0.7795481038205961, 'sample_size': 99}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7790572415065031, 'median': 0.7305845104080557, 'mode': 0.9669551406810538, 'average': 0.7790572415065031, 'sample_size': 100}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7812447935707952, 'median': 0.730707148404812, 'mode': 0.9669551406810538, 'average': 0.7812447935707952, 'sample_size': 101}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7829086252198247, 'median': 0.7339961384247629, 'mode': 0.9669551406810538, 'average': 0.7829086252198247, 'sample_size': 102}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7850163084701177, 'median': 0.7372851284447137, 'mode': 0.9669551406810538, 'average': 0.7850163084701177, 'sample_size': 103}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7868150870687496, 'median': 0.7487914928814043, 'mode': 0.9669551406810538, 'average': 0.7868150870687496, 'sample_size': 104}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7888454195728568, 'median': 0.7602978573180951, 'mode': 0.9669551406810538, 'average': 0.7888454195728568, 'sample_size': 105}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7883144898366096, 'median': 0.7487914928814043, 'mode': 0.9669551406810538, 'average': 0.7883144898366096, 'sample_size': 106}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7857527738449667, 'median': 0.7372851284447137, 'mode': 0.9669551406810538, 'average': 0.7857527738449667, 'sample_size': 107}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7849516134823181, 'median': 0.7349259979876804, 'mode': 0.9669551406810538, 'average': 0.7849516134823181, 'sample_size': 108}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7850062179652348, 'median': 0.7372851284447137, 'mode': 0.9669551406810538, 'average': 0.7850062179652348, 'sample_size': 109}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7837880572638195, 'median': 0.7349259979876804, 'mode': 0.9669551406810538, 'average': 0.7837880572638195, 'sample_size': 110}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7854382111684792, 'median': 0.7372851284447137, 'mode': 0.9669551406810538, 'average': 0.7854382111684792, 'sample_size': 111}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7873539414259035, 'median': 0.7487914928814043, 'mode': 0.9669551406810538, 'average': 0.7873539414259035, 'sample_size': 112}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7888017439068408, 'median': 0.7602978573180951, 'mode': 0.9669551406810538, 'average': 0.7888017439068408, 'sample_size': 113}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7904095293350949, 'median': 0.7612314438922986, 'mode': 0.9669551406810538, 'average': 0.7904095293350949, 'sample_size': 114}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7918055823128055, 'median': 0.7621650304665021, 'mode': 0.9669551406810538, 'average': 0.7918055823128055, 'sample_size': 115}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7933597521439695, 'median': 0.7669169806425754, 'mode': 0.9669551406810538, 'average': 0.7933597521439695, 'sample_size': 116}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7947067253886518, 'median': 0.7716689308186487, 'mode': 0.9669551406810538, 'average': 0.7947067253886518, 'sample_size': 117}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7925985853305068, 'median': 0.7669169806425754, 'mode': 0.9669551406810538, 'average': 0.7925985853305068, 'sample_size': 118}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7928270529541901, 'median': 0.7716689308186487, 'mode': 0.9669551406810538, 'average': 0.7928270529541901, 'sample_size': 119}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7941424832125314, 'median': 0.7723466143771731, 'mode': 0.9669551406810538, 'average': 0.7941424832125314, 'sample_size': 120}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7954272822159943, 'median': 0.7730242979356974, 'mode': 0.9669551406810538, 'average': 0.7954272822159943, 'sample_size': 121}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7956269457433126, 'median': 0.7733078118751012, 'mode': 0.9669551406810538, 'average': 0.7956269457433126, 'sample_size': 122}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7955431925015596, 'median': 0.7735913258145051, 'mode': 0.9669551406810538, 'average': 0.7955431925015596, 'sample_size': 123}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7942523132600594, 'median': 0.7733078118751012, 'mode': 0.9669551406810538, 'average': 0.7942523132600594, 'sample_size': 124}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7941808971300405, 'median': 0.7735913258145051, 'mode': 0.9669551406810538, 'average': 0.7941808971300405, 'sample_size': 125}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7954739424705833, 'median': 0.7739896397238668, 'mode': 0.9669551406810538, 'average': 0.7954739424705833, 'sample_size': 126}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7959405965748404, 'median': 0.7743879536332287, 'mode': 0.9669551406810538, 'average': 0.7959405965748404, 'sample_size': 127}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7953613453656154, 'median': 0.7739896397238668, 'mode': 0.9669551406810538, 'average': 0.7953613453656154, 'sample_size': 128}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7952682570111259, 'median': 0.7743879536332287, 'mode': 0.9669551406810538, 'average': 0.7952682570111259, 'sample_size': 129}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7951917727034072, 'median': 0.7757192591009338, 'mode': 0.9669551406810538, 'average': 0.7951917727034072, 'sample_size': 130}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7953795166716929, 'median': 0.7770505645686389, 'mode': 0.9669551406810538, 'average': 0.7953795166716929, 'sample_size': 131}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.795299048160015, 'median': 0.7782870371232101, 'mode': 0.9669551406810538, 'average': 0.795299048160015, 'sample_size': 132}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7966165000728598, 'median': 0.7795235096777814, 'mode': 0.9669551406810538, 'average': 0.7966165000728598, 'sample_size': 133}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7966314914923047, 'median': 0.779590578633817, 'mode': 0.9669551406810538, 'average': 0.7966314914923047, 'sample_size': 134}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7963385096722563, 'median': 0.7795235096777814, 'mode': 0.9669551406810538, 'average': 0.7963385096722563, 'sample_size': 135}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7975547964062353, 'median': 0.779590578633817, 'mode': 0.9669551406810538, 'average': 0.7975547964062353, 'sample_size': 136}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7982014561787455, 'median': 0.7796576475898526, 'mode': 0.9669551406810538, 'average': 0.7982014561787455, 'sample_size': 137}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7981040374610024, 'median': 0.7815052976131658, 'mode': 0.9669551406810538, 'average': 0.7981040374610024, 'sample_size': 138}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7982600244760227, 'median': 0.783352947636479, 'mode': 0.9669551406810538, 'average': 0.7982600244760227, 'sample_size': 139}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7981635791092669, 'median': 0.7840553103833452, 'mode': 0.9669551406810538, 'average': 0.7981635791092669, 'sample_size': 140}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7981668540820982, 'median': 0.7847576731302115, 'mode': 0.9669551406810538, 'average': 0.7981668540820982, 'sample_size': 141}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7980724232303243, 'median': 0.7847576731302115, 'mode': 0.9669551406810538, 'average': 0.7980724232303243, 'sample_size': 142}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7987820361827471, 'median': 0.7847576731302115, 'mode': 0.9669551406810538, 'average': 0.7987820361827471, 'sample_size': 143}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7970711443051198, 'median': 0.7847576731302115, 'mode': 0.9669551406810538, 'average': 0.7970711443051198, 'sample_size': 144}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7976219357254045, 'median': 0.7847576731302115, 'mode': 0.9669551406810538, 'average': 0.7976219357254045, 'sample_size': 145}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7987088466531646, 'median': 0.7847576731302115, 'mode': 0.9669551406810538, 'average': 0.7987088466531646, 'sample_size': 146}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7981712489743762, 'median': 0.7847576731302115, 'mode': 0.9669551406810538, 'average': 0.7981712489743762, 'sample_size': 147}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7980844520016284, 'median': 0.7847576731302115, 'mode': 0.9669551406810538, 'average': 0.7980844520016284, 'sample_size': 148}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7979950105326927, 'median': 0.7847576731302115, 'mode': 0.9669551406810538, 'average': 0.7979950105326927, 'sample_size': 149}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7981402853461336, 'median': 0.7847576731302115, 'mode': 0.9669551406810538, 'average': 0.7981402853461336, 'sample_size': 150}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7981434976966788, 'median': 0.7847576731302115, 'mode': 0.9669551406810538, 'average': 0.7981434976966788, 'sample_size': 151}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7982858841101798, 'median': 0.7847576731302115, 'mode': 0.9669551406810538, 'average': 0.7982858841101798, 'sample_size': 152}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7982881028433059, 'median': 0.7847576731302115, 'mode': 0.9669551406810538, 'average': 0.7982881028433059, 'sample_size': 153}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7984277010881469, 'median': 0.7847576731302115, 'mode': 0.9669551406810538, 'average': 0.7984277010881469, 'sample_size': 154}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7966983597816749, 'median': 0.7847576731302115, 'mode': 0.9669551406810538, 'average': 0.7966983597816749, 'sample_size': 155}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7951463672876732, 'median': 0.7847576731302115, 'mode': 0.9669551406810538, 'average': 0.7951463672876732, 'sample_size': 156}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7935500282558512, 'median': 0.7847576731302115, 'mode': 0.9669551406810538, 'average': 0.7935500282558512, 'sample_size': 157}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7918843938908458, 'median': 0.7847576731302115, 'mode': 0.9669551406810538, 'average': 0.7918843938908458, 'sample_size': 158}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7901931583638987, 'median': 0.7847576731302115, 'mode': 0.9669551406810538, 'average': 0.7901931583638987, 'sample_size': 159}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7898101889487771, 'median': 0.7847576731302115, 'mode': 0.9669551406810538, 'average': 0.7898101889487771, 'sample_size': 160}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7881528458193205, 'median': 0.7847576731302115, 'mode': 0.9669551406810538, 'average': 0.7881528458193205, 'sample_size': 161}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.786635329736294, 'median': 0.7847576731302115, 'mode': 0.9669551406810538, 'average': 0.786635329736294, 'sample_size': 162}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7851098761243, 'median': 0.7847576731302115, 'mode': 0.9669551406810538, 'average': 0.7851098761243, 'sample_size': 163}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7833359478685503, 'median': 0.7840553103833452, 'mode': 0.9669551406810538, 'average': 0.7833359478685503, 'sample_size': 164}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7832790910108258, 'median': 0.783352947636479, 'mode': 0.9669551406810538, 'average': 0.7832790910108258, 'sample_size': 165}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7817110118186298, 'median': 0.7815052976131658, 'mode': 0.9669551406810538, 'average': 0.7817110118186298, 'sample_size': 166}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7802060344938774, 'median': 0.7796576475898526, 'mode': 0.9669551406810538, 'average': 0.7802060344938774, 'sample_size': 167}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7785809571400313, 'median': 0.779590578633817, 'mode': 0.9669551406810538, 'average': 0.7785809571400313, 'sample_size': 168}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.777101330443883, 'median': 0.7795235096777814, 'mode': 0.9669551406810538, 'average': 0.777101330443883, 'sample_size': 169}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.775624392861316, 'median': 0.7782870371232101, 'mode': 0.9669551406810538, 'average': 0.775624392861316, 'sample_size': 170}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7740490492701303, 'median': 0.7770505645686389, 'mode': 0.9669551406810538, 'average': 0.7740490492701303, 'sample_size': 171}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7727783486473728, 'median': 0.7757192591009338, 'mode': 0.9669551406810538, 'average': 0.7727783486473728, 'sample_size': 172}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7713396080718673, 'median': 0.7743879536332287, 'mode': 0.9669551406810538, 'average': 0.7713396080718673, 'sample_size': 173}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7698215243418434, 'median': 0.7741712599886146, 'mode': 0.9669551406810538, 'average': 0.7698215243418434, 'sample_size': 174}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7684532859089471, 'median': 0.7739545663440005, 'mode': 0.9669551406810538, 'average': 0.7684532859089471, 'sample_size': 175}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7669688526881447, 'median': 0.7737729460792528, 'mode': 0.9669551406810538, 'average': 0.7669688526881447, 'sample_size': 176}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7656075707035083, 'median': 0.7735913258145051, 'mode': 0.9669551406810538, 'average': 0.7656075707035083, 'sample_size': 177}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7641558036717343, 'median': 0.7733078118751012, 'mode': 0.9669551406810538, 'average': 0.7641558036717343, 'sample_size': 178}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7627769057191809, 'median': 0.7730242979356974, 'mode': 0.9669551406810538, 'average': 0.7627769057191809, 'sample_size': 179}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7638826717174632, 'median': 0.7733078118751012, 'mode': 0.9669551406810538, 'average': 0.7638826717174632, 'sample_size': 180}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7624835089379334, 'median': 0.7730242979356974, 'mode': 0.9669551406810538, 'average': 0.7624835089379334, 'sample_size': 181}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7612084414083922, 'median': 0.7723466143771731, 'mode': 0.9669551406810538, 'average': 0.7612084414083922, 'sample_size': 182}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7612734945834122, 'median': 0.7730242979356974, 'mode': 0.9669551406810538, 'average': 0.7612734945834122, 'sample_size': 183}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7599784100753845, 'median': 0.7723466143771731, 'mode': 0.9669551406810538, 'average': 0.7599784100753845, 'sample_size': 184}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7586120026644242, 'median': 0.7716689308186487, 'mode': 0.9669551406810538, 'average': 0.7586120026644242, 'sample_size': 185}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7573849478037821, 'median': 0.7669169806425754, 'mode': 0.9669551406810538, 'average': 0.7573849478037821, 'sample_size': 186}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7561477124754595, 'median': 0.7621650304665021, 'mode': 0.9669551406810538, 'average': 0.7561477124754595, 'sample_size': 187}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7549468193164677, 'median': 0.7612314438922986, 'mode': 0.9669551406810538, 'average': 0.7549468193164677, 'sample_size': 188}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7537355765762087, 'median': 0.7602978573180951, 'mode': 0.9669551406810538, 'average': 0.7537355765762087, 'sample_size': 189}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.752560019849939, 'median': 0.7586884015519295, 'mode': 0.9669551406810538, 'average': 0.752560019849939, 'sample_size': 190}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7527790742636044, 'median': 0.7602978573180951, 'mode': 0.9669551406810538, 'average': 0.7527790742636044, 'sample_size': 191}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7529795397429182, 'median': 0.7612314438922986, 'mode': 0.9669551406810538, 'average': 0.7529795397429182, 'sample_size': 192}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.754259438500727, 'median': 0.7621650304665021, 'mode': 0.9669551406810538, 'average': 0.754259438500727, 'sample_size': 193}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7552995949080162, 'median': 0.7669169806425754, 'mode': 0.9669551406810538, 'average': 0.7552995949080162, 'sample_size': 194}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7548388139355214, 'median': 0.7621650304665021, 'mode': 0.9669551406810538, 'average': 0.7548388139355214, 'sample_size': 195}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7558654005048038, 'median': 0.7669169806425754, 'mode': 0.9669551406810538, 'average': 0.7558654005048038, 'sample_size': 196}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7561242670219184, 'median': 0.7716689308186487, 'mode': 0.9669551406810538, 'average': 0.7561242670219184, 'sample_size': 197}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7565969464113758, 'median': 0.7723466143771731, 'mode': 0.9669551406810538, 'average': 0.7565969464113758, 'sample_size': 198}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7572433401959284, 'median': 0.7730242979356974, 'mode': 0.9669551406810538, 'average': 0.7572433401959284, 'sample_size': 199}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7569356568921728, 'median': 0.7723466143771731, 'mode': 0.9669551406810538, 'average': 0.7569356568921728, 'sample_size': 200}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7579262744276092, 'median': 0.7730242979356974, 'mode': 0.9560497815148686, 'average': 0.7579262744276092, 'sample_size': 201}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7591246592076705, 'median': 0.7730687351863839, 'mode': 0.9560497815148686, 'average': 0.7591246592076705, 'sample_size': 202}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7600696393188239, 'median': 0.7731131724370702, 'mode': 0.9560497815148686, 'average': 0.7600696393188239, 'sample_size': 203}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7603261879980497, 'median': 0.7733522491257876, 'mode': 0.9560497815148686, 'average': 0.7603261879980497, 'sample_size': 204}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7613570575213998, 'median': 0.7735913258145051, 'mode': 0.9560497815148686, 'average': 0.7613570575213998, 'sample_size': 205}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7621951370541705, 'median': 0.7737729460792528, 'mode': 0.9560497815148686, 'average': 0.7621951370541705, 'sample_size': 206}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7623650731913211, 'median': 0.7739545663440005, 'mode': 0.9560497815148686, 'average': 0.7623650731913211, 'sample_size': 207}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7621642245413318, 'median': 0.7737729460792528, 'mode': 0.9560497815148686, 'average': 0.7621642245413318, 'sample_size': 208}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7630675326620519, 'median': 0.7739545663440005, 'mode': 0.9560497815148686, 'average': 0.7630675326620519, 'sample_size': 209}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7641957825065183, 'median': 0.7741712599886146, 'mode': 0.9560497815148686, 'average': 0.7641957825065183, 'sample_size': 210}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7650809002281548, 'median': 0.7743879536332287, 'mode': 0.9509556217718045, 'average': 0.7650809002281548, 'sample_size': 211}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7660553037189881, 'median': 0.7757192591009338, 'mode': 0.9509556217718045, 'average': 0.7660553037189881, 'sample_size': 212}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7669233803295648, 'median': 0.7770505645686389, 'mode': 0.9509556217718045, 'average': 0.7669233803295648, 'sample_size': 213}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7668017048132599, 'median': 0.7757192591009338, 'mode': 0.9509556217718045, 'average': 0.7668017048132599, 'sample_size': 214}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7656847214989339, 'median': 0.7743879536332287, 'mode': 0.9509556217718045, 'average': 0.7656847214989339, 'sample_size': 215}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7655001053131237, 'median': 0.7741712599886146, 'mode': 0.9509556217718045, 'average': 0.7655001053131237, 'sample_size': 216}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7657290535390314, 'median': 0.7743879536332287, 'mode': 0.9509556217718045, 'average': 0.7657290535390314, 'sample_size': 217}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7652798404978859, 'median': 0.7741712599886146, 'mode': 0.9509556217718045, 'average': 0.7652798404978859, 'sample_size': 218}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7661509361189679, 'median': 0.7743879536332287, 'mode': 0.9509556217718045, 'average': 0.7661509361189679, 'sample_size': 219}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7669909574173899, 'median': 0.7757192591009338, 'mode': 0.9509556217718045, 'average': 0.7669909574173899, 'sample_size': 220}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7680452969765872, 'median': 0.7770505645686389, 'mode': 0.9509556217718045, 'average': 0.7680452969765872, 'sample_size': 221}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7689624552797776, 'median': 0.7782870371232101, 'mode': 0.9509556217718045, 'average': 0.7689624552797776, 'sample_size': 222}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7699984980812136, 'median': 0.7795235096777814, 'mode': 0.9509556217718045, 'average': 0.7699984980812136, 'sample_size': 223}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7708987478231941, 'median': 0.779590578633817, 'mode': 0.9509556217718045, 'average': 0.7708987478231941, 'sample_size': 224}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7719169756106465, 'median': 0.7796576475898526, 'mode': 0.9509556217718045, 'average': 0.7719169756106465, 'sample_size': 225}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7725895307549588, 'median': 0.7815052976131658, 'mode': 0.9509556217718045, 'average': 0.7725895307549588, 'sample_size': 226}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7726856095307519, 'median': 0.783352947636479, 'mode': 0.9509556217718045, 'average': 0.7726856095307519, 'sample_size': 227}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7726811504135935, 'median': 0.7815052976131658, 'mode': 0.9509556217718045, 'average': 0.7726811504135935, 'sample_size': 228}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.772036683614203, 'median': 0.7796576475898526, 'mode': 0.9509556217718045, 'average': 0.772036683614203, 'sample_size': 229}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.772035084689005, 'median': 0.779590578633817, 'mode': 0.9509556217718045, 'average': 0.772035084689005, 'sample_size': 230}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7728069819798654, 'median': 0.7796576475898526, 'mode': 0.9509556217718045, 'average': 0.7728069819798654, 'sample_size': 231}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7731577175806066, 'median': 0.7815052976131658, 'mode': 0.9509556217718045, 'average': 0.7731577175806066, 'sample_size': 232}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.77299987661168, 'median': 0.7796576475898526, 'mode': 0.9509556217718045, 'average': 0.77299987661168, 'sample_size': 233}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7730663141814662, 'median': 0.7815052976131658, 'mode': 0.9509556217718045, 'average': 0.7730663141814662, 'sample_size': 234}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7730603678692841, 'median': 0.7796576475898526, 'mode': 0.9509556217718045, 'average': 0.7730603678692841, 'sample_size': 235}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7731507875514482, 'median': 0.7815052976131658, 'mode': 0.9509556217718045, 'average': 0.7731507875514482, 'sample_size': 236}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7731776766743442, 'median': 0.7796576475898526, 'mode': 0.9509556217718045, 'average': 0.7731776766743442, 'sample_size': 237}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7738661562992473, 'median': 0.7815052976131658, 'mode': 0.9509556217718045, 'average': 0.7738661562992473, 'sample_size': 238}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.77394563845454, 'median': 0.783352947636479, 'mode': 0.9509556217718045, 'average': 0.77394563845454, 'sample_size': 239}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7738371839955922, 'median': 0.7815052976131658, 'mode': 0.9509556217718045, 'average': 0.7738371839955922, 'sample_size': 240}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7745616072415922, 'median': 0.783352947636479, 'mode': 0.9509556217718045, 'average': 0.7745616072415922, 'sample_size': 241}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.77506966417896, 'median': 0.7840553103833452, 'mode': 0.9509556217718045, 'average': 0.77506966417896, 'sample_size': 242}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7750879927612596, 'median': 0.783352947636479, 'mode': 0.9509556217718045, 'average': 0.7750879927612596, 'sample_size': 243}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7751671379255989, 'median': 0.7840553103833452, 'mode': 0.9509556217718045, 'average': 0.7751671379255989, 'sample_size': 244}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7751849190347914, 'median': 0.783352947636479, 'mode': 0.9509556217718045, 'average': 0.7751849190347914, 'sample_size': 245}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7752567786786103, 'median': 0.7840553103833452, 'mode': 0.9509556217718045, 'average': 0.7752567786786103, 'sample_size': 246}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7752740528931819, 'median': 0.783352947636479, 'mode': 0.9509556217718045, 'average': 0.7752740528931819, 'sample_size': 247}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7758548408307634, 'median': 0.7840553103833452, 'mode': 0.9509556217718045, 'average': 0.7758548408307634, 'sample_size': 248}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7749790982545576, 'median': 0.783352947636479, 'mode': 0.9509556217718045, 'average': 0.7749790982545576, 'sample_size': 249}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7753581249639475, 'median': 0.7840553103833452, 'mode': 0.9509556217718045, 'average': 0.7753581249639475, 'sample_size': 250}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7760097562926151, 'median': 0.7847576731302115, 'mode': 0.9509556217718045, 'average': 0.7760097562926151, 'sample_size': 251}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7757477699738576, 'median': 0.7840553103833452, 'mode': 0.9509556217718045, 'average': 0.7757477699738576, 'sample_size': 252}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7757316480799636, 'median': 0.783352947636479, 'mode': 0.9509556217718045, 'average': 0.7757316480799636, 'sample_size': 253}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7757465766689314, 'median': 0.7815052976131658, 'mode': 0.9509556217718045, 'average': 0.7757465766689314, 'sample_size': 254}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7758197250461513, 'median': 0.783352947636479, 'mode': 0.9509556217718045, 'average': 0.7758197250461513, 'sample_size': 255}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7758862979616516, 'median': 0.7840553103833452, 'mode': 0.9509556217718045, 'average': 0.7758862979616516, 'sample_size': 256}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7759583334281822, 'median': 0.7847576731302115, 'mode': 0.9509556217718045, 'average': 0.7759583334281822, 'sample_size': 257}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7760238530327792, 'median': 0.7847576731302115, 'mode': 0.9509556217718045, 'average': 0.7760238530327792, 'sample_size': 258}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7760948011402203, 'median': 0.7847576731302115, 'mode': 0.9509556217718045, 'average': 0.7760948011402203, 'sample_size': 259}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7761531613138803, 'median': 0.7847576731302115, 'mode': 0.9509556217718045, 'average': 0.7761531613138803, 'sample_size': 260}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7760995669428177, 'median': 0.7847576731302115, 'mode': 0.9509556217718045, 'average': 0.7760995669428177, 'sample_size': 261}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7755945429884628, 'median': 0.7847576731302115, 'mode': 0.9509556217718045, 'average': 0.7755945429884628, 'sample_size': 262}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7755434802032082, 'median': 0.7847576731302115, 'mode': 0.9509556217718045, 'average': 0.7755434802032082, 'sample_size': 263}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7762562464959197, 'median': 0.7847576731302115, 'mode': 0.9509556217718045, 'average': 0.7762562464959197, 'sample_size': 264}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7766511805913114, 'median': 0.7847576731302115, 'mode': 0.9509556217718045, 'average': 0.7766511805913114, 'sample_size': 265}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7764119272959429, 'median': 0.7847576731302115, 'mode': 0.9509556217718045, 'average': 0.7764119272959429, 'sample_size': 266}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.776357485608716, 'median': 0.7847576731302115, 'mode': 0.9509556217718045, 'average': 0.776357485608716, 'sample_size': 267}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7763045286865436, 'median': 0.7840553103833452, 'mode': 0.9509556217718045, 'average': 0.7763045286865436, 'sample_size': 268}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7763601566330316, 'median': 0.7847576731302115, 'mode': 0.9509556217718045, 'average': 0.7763601566330316, 'sample_size': 269}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7763006666355688, 'median': 0.7840553103833452, 'mode': 0.9509556217718045, 'average': 0.7763006666355688, 'sample_size': 270}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7769960101028136, 'median': 0.7847576731302115, 'mode': 0.9509556217718045, 'average': 0.7769960101028136, 'sample_size': 271}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7769986168810408, 'median': 0.7840553103833452, 'mode': 0.9509556217718045, 'average': 0.7769986168810408, 'sample_size': 272}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7768324759591752, 'median': 0.783352947636479, 'mode': 0.9509556217718045, 'average': 0.7768324759591752, 'sample_size': 273}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7775393707939764, 'median': 0.7840553103833452, 'mode': 0.9509556217718045, 'average': 0.7775393707939764, 'sample_size': 274}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7778673797515454, 'median': 0.7847576731302115, 'mode': 0.9509556217718045, 'average': 0.7778673797515454, 'sample_size': 275}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7778037220615692, 'median': 0.7840553103833452, 'mode': 0.9509556217718045, 'average': 0.7778037220615692, 'sample_size': 276}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7778523311743137, 'median': 0.7847576731302115, 'mode': 0.9509556217718045, 'average': 0.7778523311743137, 'sample_size': 277}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.777789185584903, 'median': 0.7840553103833452, 'mode': 0.9509556217718045, 'average': 0.777789185584903, 'sample_size': 278}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7777888840372171, 'median': 0.783352947636479, 'mode': 0.9509556217718045, 'average': 0.7777888840372171, 'sample_size': 279}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7777264160846489, 'median': 0.7815052976131658, 'mode': 0.9509556217718045, 'average': 0.7777264160846489, 'sample_size': 280}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7781168548781237, 'median': 0.783352947636479, 'mode': 0.9509556217718045, 'average': 0.7781168548781237, 'sample_size': 281}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7773241922060384, 'median': 0.7815052976131658, 'mode': 0.9509556217718045, 'average': 0.7773241922060384, 'sample_size': 282}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7776232310875982, 'median': 0.783352947636479, 'mode': 0.9509556217718045, 'average': 0.7776232310875982, 'sample_size': 283}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7782858659340746, 'median': 0.7840553103833452, 'mode': 0.9509556217718045, 'average': 0.7782858659340746, 'sample_size': 284}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7780183830111911, 'median': 0.783352947636479, 'mode': 0.9509556217718045, 'average': 0.7780183830111911, 'sample_size': 285}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7779629517085874, 'median': 0.7815052976131658, 'mode': 0.9509556217718045, 'average': 0.7779629517085874, 'sample_size': 286}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7779014008570526, 'median': 0.7796576475898526, 'mode': 0.9509556217718045, 'average': 0.7779014008570526, 'sample_size': 287}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7779478142092565, 'median': 0.7815052976131658, 'mode': 0.9509556217718045, 'average': 0.7779478142092565, 'sample_size': 288}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7779469742077734, 'median': 0.7796576475898526, 'mode': 0.9509556217718045, 'average': 0.7779469742077734, 'sample_size': 289}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.777992910318408, 'median': 0.7815052976131658, 'mode': 0.9509556217718045, 'average': 0.777992910318408, 'sample_size': 290}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7779919211206834, 'median': 0.7796576475898526, 'mode': 0.9509556217718045, 'average': 0.7779919211206834, 'sample_size': 291}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7780373886726394, 'median': 0.7815052976131658, 'mode': 0.9509556217718045, 'average': 0.7780373886726394, 'sample_size': 292}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7786449395014525, 'median': 0.783352947636479, 'mode': 0.9509556217718045, 'average': 0.7786449395014525, 'sample_size': 293}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.778259913534684, 'median': 0.7815052976131658, 'mode': 0.9509556217718045, 'average': 0.778259913534684, 'sample_size': 294}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7788625910532609, 'median': 0.783352947636479, 'mode': 0.9560497815148686, 'average': 0.7788625910532609, 'sample_size': 295}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7789571840036769, 'median': 0.7840553103833452, 'mode': 0.9560497815148686, 'average': 0.7789571840036769, 'sample_size': 296}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7791954250882924, 'median': 0.7847576731302115, 'mode': 0.9560497815148686, 'average': 0.7791954250882924, 'sample_size': 297}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7795512434924838, 'median': 0.7847576731302115, 'mode': 0.9560497815148686, 'average': 0.7795512434924838, 'sample_size': 298}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7792708268903178, 'median': 0.7847576731302115, 'mode': 0.9560497815148686, 'average': 0.7792708268903178, 'sample_size': 299}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7798600900723996, 'median': 0.7847576731302115, 'mode': 0.9560497815148686, 'average': 0.7798600900723996, 'sample_size': 300}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7805914518994016, 'median': 0.7847576731302115, 'mode': 0.9560497815148686, 'average': 0.7805914518994016, 'sample_size': 301}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7811555716671911, 'median': 0.7847576731302115, 'mode': 0.9560497815148686, 'average': 0.7811555716671911, 'sample_size': 302}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7812587069748269, 'median': 0.7847576731302115, 'mode': 0.9560497815148686, 'average': 0.7812587069748269, 'sample_size': 303}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7818850087291362, 'median': 0.7847576731302115, 'mode': 0.9560497815148686, 'average': 0.7818850087291362, 'sample_size': 304}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7823837511309165, 'median': 0.7847576731302115, 'mode': 0.9560497815148686, 'average': 0.7823837511309165, 'sample_size': 305}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7824327320665814, 'median': 0.7847576731302115, 'mode': 0.9560497815148686, 'average': 0.7824327320665814, 'sample_size': 306}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7822312852324672, 'median': 0.7847576731302115, 'mode': 0.9560497815148686, 'average': 0.7822312852324672, 'sample_size': 307}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7827790915199326, 'median': 0.7847576731302115, 'mode': 0.9509556217718045, 'average': 0.7827790915199326, 'sample_size': 308}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7834820718062759, 'median': 0.7847576731302115, 'mode': 0.9509556217718045, 'average': 0.7834820718062759, 'sample_size': 309}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7840223090642292, 'median': 0.7847576731302115, 'mode': 0.9509556217718045, 'average': 0.7840223090642292, 'sample_size': 310}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7846256278141348, 'median': 0.7847576731302115, 'mode': 0.9509556217718045, 'average': 0.7846256278141348, 'sample_size': 311}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7851587367691274, 'median': 0.7850414850689503, 'mode': 0.9509556217718045, 'average': 0.7851587367691274, 'sample_size': 312}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7850172865552972, 'median': 0.7847576731302115, 'mode': 0.9509556217718045, 'average': 0.7850172865552972, 'sample_size': 313}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7841944617326153, 'median': 0.7847576731302115, 'mode': 0.9509556217718045, 'average': 0.7841944617326153, 'sample_size': 314}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7840091066965243, 'median': 0.7847576731302115, 'mode': 0.9509556217718045, 'average': 0.7840091066965243, 'sample_size': 315}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7841077546827224, 'median': 0.7847576731302115, 'mode': 0.9509556217718045, 'average': 0.7841077546827224, 'sample_size': 316}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7837408551744781, 'median': 0.7847576731302115, 'mode': 0.9509556217718045, 'average': 0.7837408551744781, 'sample_size': 317}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7842827071441019, 'median': 0.7847576731302115, 'mode': 0.9509556217718045, 'average': 0.7842827071441019, 'sample_size': 318}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7848051927698941, 'median': 0.7847576731302115, 'mode': 0.9509556217718045, 'average': 0.7848051927698941, 'sample_size': 319}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7854776765424882, 'median': 0.7850414850689503, 'mode': 0.9509556217718045, 'average': 0.7854776765424882, 'sample_size': 320}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7860576664606888, 'median': 0.7853252970076892, 'mode': 0.9509556217718045, 'average': 0.7860576664606888, 'sample_size': 321}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7867220836455934, 'median': 0.7853252970076892, 'mode': 0.9509556217718045, 'average': 0.7867220836455934, 'sample_size': 322}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7872946296413805, 'median': 0.7853252970076892, 'mode': 0.9509556217718045, 'average': 0.7872946296413805, 'sample_size': 323}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7879511276980429, 'median': 0.7853252970076892, 'mode': 0.9509556217718045, 'average': 0.7879511276980429, 'sample_size': 324}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7875167035868094, 'median': 0.7853252970076892, 'mode': 0.9509556217718045, 'average': 0.7875167035868094, 'sample_size': 325}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7881684928396104, 'median': 0.7853252970076892, 'mode': 0.9509556217718045, 'average': 0.7881684928396104, 'sample_size': 326}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7881643763002705, 'median': 0.7853252970076892, 'mode': 0.9509556217718045, 'average': 0.7881643763002705, 'sample_size': 327}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7882630473201276, 'median': 0.7853252970076892, 'mode': 0.9509556217718045, 'average': 0.7882630473201276, 'sample_size': 328}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7886732628838236, 'median': 0.7853252970076892, 'mode': 0.9509556217718045, 'average': 0.7886732628838236, 'sample_size': 329}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7883273903859447, 'median': 0.7853252970076892, 'mode': 0.9509556217718045, 'average': 0.7883273903859447, 'sample_size': 330}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7889668846748089, 'median': 0.7853252970076892, 'mode': 0.9509556217718045, 'average': 0.7889668846748089, 'sample_size': 331}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.789470146412279, 'median': 0.7853252970076892, 'mode': 0.9509556217718045, 'average': 0.789470146412279, 'sample_size': 332}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.790003134383056, 'median': 0.7853252970076892, 'mode': 0.9509556217718045, 'average': 0.790003134383056, 'sample_size': 333}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7899539972316532, 'median': 0.7853252970076892, 'mode': 0.9509556217718045, 'average': 0.7899539972316532, 'sample_size': 334}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7904773041295389, 'median': 0.7853252970076892, 'mode': 0.9509556217718045, 'average': 0.7904773041295389, 'sample_size': 335}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7910051685750168, 'median': 0.7860738407415431, 'mode': 0.9509556217718045, 'average': 0.7910051685750168, 'sample_size': 336}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7909558593318662, 'median': 0.7853252970076892, 'mode': 0.9509556217718045, 'average': 0.7909558593318662, 'sample_size': 337}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7907394153899623, 'median': 0.7853252970076892, 'mode': 0.9509556217718045, 'average': 0.7907394153899623, 'sample_size': 338}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.791259225789051, 'median': 0.7853252970076892, 'mode': 0.9509556217718045, 'average': 0.791259225789051, 'sample_size': 339}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.791743903894127, 'median': 0.7860738407415431, 'mode': 0.9509556217718045, 'average': 0.791743903894127, 'sample_size': 340}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7922577198377836, 'median': 0.7868223844753969, 'mode': 0.9509556217718045, 'average': 0.7922577198377836, 'sample_size': 341}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.792763579744759, 'median': 0.7868223844753969, 'mode': 0.9509556217718045, 'average': 0.792763579744759, 'sample_size': 342}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7932714268611912, 'median': 0.7868223844753969, 'mode': 0.9509556217718045, 'average': 0.7932714268611912, 'sample_size': 343}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7930861905541897, 'median': 0.7868223844753969, 'mode': 0.9509556217718045, 'average': 0.7930861905541897, 'sample_size': 344}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7922995759248171, 'median': 0.7868223844753969, 'mode': 0.9509556217718045, 'average': 0.7922995759248171, 'sample_size': 345}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7920160270627671, 'median': 0.7860738407415431, 'mode': 0.9509556217718045, 'average': 0.7920160270627671, 'sample_size': 346}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7919804121363321, 'median': 0.7853252970076892, 'mode': 0.9509556217718045, 'average': 0.7919804121363321, 'sample_size': 347}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7915737439881803, 'median': 0.7853252970076892, 'mode': 0.9509556217718045, 'average': 0.7915737439881803, 'sample_size': 348}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.792170953890793, 'median': 0.7853252970076892, 'mode': 0.9509556217718045, 'average': 0.792170953890793, 'sample_size': 349}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7926703372816223, 'median': 0.7860738407415431, 'mode': 0.9509556217718045, 'average': 0.7926703372816223, 'sample_size': 350}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7931358057837112, 'median': 0.7868223844753969, 'mode': 0.9560497815148686, 'average': 0.7931358057837112, 'sample_size': 351}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7936248001082558, 'median': 0.7868223844753969, 'mode': 0.9560497815148686, 'average': 0.7936248001082558, 'sample_size': 352}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7940849275343369, 'median': 0.7868223844753969, 'mode': 0.9560497815148686, 'average': 0.7940849275343369, 'sample_size': 353}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7945684780441928, 'median': 0.7876843262085198, 'mode': 0.9560497815148686, 'average': 0.7945684780441928, 'sample_size': 354}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7950233549553778, 'median': 0.7885462679416428, 'mode': 0.9560497815148686, 'average': 0.7950233549553778, 'sample_size': 355}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7946068941031075, 'median': 0.7876843262085198, 'mode': 0.9560497815148686, 'average': 0.7946068941031075, 'sample_size': 356}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7941151088939808, 'median': 0.7868223844753969, 'mode': 0.9560497815148686, 'average': 0.7941151088939808, 'sample_size': 357}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7937694806636694, 'median': 0.7868223844753969, 'mode': 0.9560497815148686, 'average': 0.7937694806636694, 'sample_size': 358}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7933352352173962, 'median': 0.7868223844753969, 'mode': 0.9560497815148686, 'average': 0.7933352352173962, 'sample_size': 359}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7931830449579382, 'median': 0.7860738407415431, 'mode': 0.9560497815148686, 'average': 0.7931830449579382, 'sample_size': 360}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7927774500731438, 'median': 0.7853252970076892, 'mode': 0.9560497815148686, 'average': 0.7927774500731438, 'sample_size': 361}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7924257093416476, 'median': 0.7853252970076892, 'mode': 0.9560497815148686, 'average': 0.7924257093416476, 'sample_size': 362}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7920422310688642, 'median': 0.7853252970076892, 'mode': 0.9560497815148686, 'average': 0.7920422310688642, 'sample_size': 363}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7915919744637717, 'median': 0.7853252970076892, 'mode': 0.9560497815148686, 'average': 0.7915919744637717, 'sample_size': 364}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7912485037121055, 'median': 0.7853252970076892, 'mode': 0.9560497815148686, 'average': 0.7912485037121055, 'sample_size': 365}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7907950642798653, 'median': 0.7853252970076892, 'mode': 0.9560497815148686, 'average': 0.7907950642798653, 'sample_size': 366}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7903770256657034, 'median': 0.7853252970076892, 'mode': 0.9560497815148686, 'average': 0.7903770256657034, 'sample_size': 367}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7898963113235382, 'median': 0.7853252970076892, 'mode': 0.9560497815148686, 'average': 0.7898963113235382, 'sample_size': 368}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7895259232070007, 'median': 0.7853252970076892, 'mode': 0.9560497815148686, 'average': 0.7895259232070007, 'sample_size': 369}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7891905755909588, 'median': 0.7850414850689503, 'mode': 0.9560497815148686, 'average': 0.7891905755909588, 'sample_size': 370}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7888240864285069, 'median': 0.7847576731302115, 'mode': 0.9560497815148686, 'average': 0.7888240864285069, 'sample_size': 371}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7884945193953808, 'median': 0.7847576731302115, 'mode': 0.9560497815148686, 'average': 0.7884945193953808, 'sample_size': 372}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7881318614246725, 'median': 0.7847576731302115, 'mode': 0.9560497815148686, 'average': 0.7881318614246725, 'sample_size': 373}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7876111462182588, 'median': 0.7847576731302115, 'mode': 0.9560497815148686, 'average': 0.7876111462182588, 'sample_size': 374}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7874791732996164, 'median': 0.7847576731302115, 'mode': 0.9560497815148686, 'average': 0.7874791732996164, 'sample_size': 375}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7870122680074914, 'median': 0.7847576731302115, 'mode': 0.9560497815148686, 'average': 0.7870122680074914, 'sample_size': 376}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7866156548020228, 'median': 0.7847576731302115, 'mode': 0.9560497815148686, 'average': 0.7866156548020228, 'sample_size': 377}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7865217232972532, 'median': 0.7847576731302115, 'mode': 0.9560497815148686, 'average': 0.7865217232972532, 'sample_size': 378}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7861529675406566, 'median': 0.7847576731302115, 'mode': 0.9560497815148686, 'average': 0.7861529675406566, 'sample_size': 379}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7858031520900792, 'median': 0.7847576731302115, 'mode': 0.9560497815148686, 'average': 0.7858031520900792, 'sample_size': 380}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7854872574790068, 'median': 0.7847576731302115, 'mode': 0.9560497815148686, 'average': 0.7854872574790068, 'sample_size': 381}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7851750530094429, 'median': 0.7840553103833452, 'mode': 0.9560497815148686, 'average': 0.7851750530094429, 'sample_size': 382}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7848624479239653, 'median': 0.783352947636479, 'mode': 0.9560497815148686, 'average': 0.7848624479239653, 'sample_size': 383}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7845534966275634, 'median': 0.7815052976131658, 'mode': 0.9560497815148686, 'average': 0.7845534966275634, 'sample_size': 384}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7842441298967683, 'median': 0.7796576475898526, 'mode': 0.9560497815148686, 'average': 0.7842441298967683, 'sample_size': 385}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7842508093127752, 'median': 0.7815052976131658, 'mode': 0.9560497815148686, 'average': 0.7842508093127752, 'sample_size': 386}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7843445500401672, 'median': 0.783352947636479, 'mode': 0.9560497815148686, 'average': 0.7843445500401672, 'sample_size': 387}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7847024866838164, 'median': 0.7840553103833452, 'mode': 0.9560497815148686, 'average': 0.7847024866838164, 'sample_size': 388}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7844192806475695, 'median': 0.783352947636479, 'mode': 0.9560497815148686, 'average': 0.7844192806475695, 'sample_size': 389}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7849720517228321, 'median': 0.7840553103833452, 'mode': 0.9560497815148686, 'average': 0.7849720517228321, 'sample_size': 390}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.785409590673707, 'median': 0.7847576731302115, 'mode': 0.9560497815148686, 'average': 0.785409590673707, 'sample_size': 391}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.785872717076787, 'median': 0.7847576731302115, 'mode': 0.9560497815148686, 'average': 0.785872717076787, 'sample_size': 392}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7858414667173408, 'median': 0.7847576731302115, 'mode': 0.9560497815148686, 'average': 0.7858414667173408, 'sample_size': 393}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7862968482942597, 'median': 0.7847576731302115, 'mode': 0.9560497815148686, 'average': 0.7862968482942597, 'sample_size': 394}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7867564505968315, 'median': 0.7847576731302115, 'mode': 0.9560497815148686, 'average': 0.7867564505968315, 'sample_size': 395}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7867252170186407, 'median': 0.7847576731302115, 'mode': 0.9560497815148686, 'average': 0.7867252170186407, 'sample_size': 396}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7865515963384131, 'median': 0.7847576731302115, 'mode': 0.9560497815148686, 'average': 0.7865515963384131, 'sample_size': 397}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.787004871575455, 'median': 0.7847576731302115, 'mode': 0.9560497815148686, 'average': 0.787004871575455, 'sample_size': 398}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7874285430289372, 'median': 0.7847576731302115, 'mode': 0.9560497815148686, 'average': 0.7874285430289372, 'sample_size': 399}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7878773595230675, 'median': 0.7847576731302115, 'mode': 0.9560497815148686, 'average': 0.7878773595230675, 'sample_size': 400}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7883197147562354, 'median': 0.7847576731302115, 'mode': 0.9560497815148686, 'average': 0.7883197147562354, 'sample_size': 401}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7887640814873915, 'median': 0.7847576731302115, 'mode': 0.9560497815148686, 'average': 0.7887640814873915, 'sample_size': 402}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7886171486232856, 'median': 0.7847576731302115, 'mode': 0.9560497815148686, 'average': 0.7886171486232856, 'sample_size': 403}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7879564728678335, 'median': 0.7847576731302115, 'mode': 0.9560497815148686, 'average': 0.7879564728678335, 'sample_size': 404}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7877249548352104, 'median': 0.7847576731302115, 'mode': 0.9560497815148686, 'average': 0.7877249548352104, 'sample_size': 405}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7877050846203204, 'median': 0.7847576731302115, 'mode': 0.9560497815148686, 'average': 0.7877050846203204, 'sample_size': 406}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7873678728560922, 'median': 0.7847576731302115, 'mode': 0.9560497815148686, 'average': 0.7873678728560922, 'sample_size': 407}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7878890300304647, 'median': 0.7847576731302115, 'mode': 0.9560497815148686, 'average': 0.7878890300304647, 'sample_size': 408}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.788326844481933, 'median': 0.7847576731302115, 'mode': 0.9560497815148686, 'average': 0.788326844481933, 'sample_size': 409}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7887359248161597, 'median': 0.7847576731302115, 'mode': 0.9560497815148686, 'average': 0.7887359248161597, 'sample_size': 410}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7891654281816275, 'median': 0.7847576731302115, 'mode': 0.9560497815148686, 'average': 0.7891654281816275, 'sample_size': 411}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7895704872916595, 'median': 0.7847576731302115, 'mode': 0.9560497815148686, 'average': 0.7895704872916595, 'sample_size': 412}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7899958900052957, 'median': 0.7847576731302115, 'mode': 0.9560497815148686, 'average': 0.7899958900052957, 'sample_size': 413}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.790396986361599, 'median': 0.7847576731302115, 'mode': 0.9560497815148686, 'average': 0.790396986361599, 'sample_size': 414}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.790626733696493, 'median': 0.7847576731302115, 'mode': 0.9560497815148686, 'average': 0.790626733696493, 'sample_size': 415}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7904742611371371, 'median': 0.7847576731302115, 'mode': 0.9560497815148686, 'average': 0.7904742611371371, 'sample_size': 416}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7904438985077461, 'median': 0.7847576731302115, 'mode': 0.9560497815148686, 'average': 0.7904438985077461, 'sample_size': 417}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7904352345985779, 'median': 0.7847576731302115, 'mode': 0.9560497815148686, 'average': 0.7904352345985779, 'sample_size': 418}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7904744395383817, 'median': 0.7847576731302115, 'mode': 0.9560497815148686, 'average': 0.7904744395383817, 'sample_size': 419}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7904728502712272, 'median': 0.7847576731302115, 'mode': 0.9560497815148686, 'average': 0.7904728502712272, 'sample_size': 420}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7908980664380709, 'median': 0.7847576731302115, 'mode': 0.9560497815148686, 'average': 0.7908980664380709, 'sample_size': 421}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.790909547278001, 'median': 0.7850414850689503, 'mode': 0.9560497815148686, 'average': 0.790909547278001, 'sample_size': 422}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7908577998500324, 'median': 0.7847576731302115, 'mode': 0.9560497815148686, 'average': 0.7908577998500324, 'sample_size': 423}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7912554729393037, 'median': 0.7850414850689503, 'mode': 0.9560497815148686, 'average': 0.7912554729393037, 'sample_size': 424}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7914716553110047, 'median': 0.7853252970076892, 'mode': 0.9560497815148686, 'average': 0.7914716553110047, 'sample_size': 425}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7914677475457994, 'median': 0.7853252970076892, 'mode': 0.9560497815148686, 'average': 0.7914677475457994, 'sample_size': 426}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7915037999037163, 'median': 0.7853252970076892, 'mode': 0.9560497815148686, 'average': 0.7915037999037163, 'sample_size': 427}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7914998352949075, 'median': 0.7853252970076892, 'mode': 0.9560497815148686, 'average': 0.7914998352949075, 'sample_size': 428}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7915097260771772, 'median': 0.7853252970076892, 'mode': 0.9560497815148686, 'average': 0.7915097260771772, 'sample_size': 429}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7915057661266106, 'median': 0.7853252970076892, 'mode': 0.9560497815148686, 'average': 0.7915057661266106, 'sample_size': 430}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7917823666914411, 'median': 0.7853252970076892, 'mode': 0.9560497815148686, 'average': 0.7917823666914411, 'sample_size': 431}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7912148159108264, 'median': 0.7853252970076892, 'mode': 0.9560497815148686, 'average': 0.7912148159108264, 'sample_size': 432}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7914124255400659, 'median': 0.7853252970076892, 'mode': 0.9560497815148686, 'average': 0.7914124255400659, 'sample_size': 433}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7918257843582968, 'median': 0.7853252970076892, 'mode': 0.9560497815148686, 'average': 0.7918257843582968, 'sample_size': 434}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7916370977182208, 'median': 0.7853252970076892, 'mode': 0.9560497815148686, 'average': 0.7916370977182208, 'sample_size': 435}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7916260547979392, 'median': 0.7853252970076892, 'mode': 0.9560497815148686, 'average': 0.7916260547979392, 'sample_size': 436}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7916218920806293, 'median': 0.7853252970076892, 'mode': 0.9560497815148686, 'average': 0.7916218920806293, 'sample_size': 437}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7916566870858707, 'median': 0.7860738407415431, 'mode': 0.9560497815148686, 'average': 0.7916566870858707, 'sample_size': 438}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7916659952722094, 'median': 0.7868223844753969, 'mode': 0.9560497815148686, 'average': 0.7916659952722094, 'sample_size': 439}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7917005318838098, 'median': 0.7868223844753969, 'mode': 0.9560497815148686, 'average': 0.7917005318838098, 'sample_size': 440}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7917096984348411, 'median': 0.7868223844753969, 'mode': 0.9560497815148686, 'average': 0.7917096984348411, 'sample_size': 441}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7917439798962472, 'median': 0.7868223844753969, 'mode': 0.9560497815148686, 'average': 0.7917439798962472, 'sample_size': 442}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.791756952926302, 'median': 0.7868223844753969, 'mode': 0.9560497815148686, 'average': 0.791756952926302, 'sample_size': 443}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7916081542650784, 'median': 0.7868223844753969, 'mode': 0.9560497815148686, 'average': 0.7916081542650784, 'sample_size': 444}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7916731437404679, 'median': 0.7868223844753969, 'mode': 0.9560497815148686, 'average': 0.7916731437404679, 'sample_size': 445}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7918032819521137, 'median': 0.7868223844753969, 'mode': 0.9560497815148686, 'average': 0.7918032819521137, 'sample_size': 446}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7919029476890821, 'median': 0.7868223844753969, 'mode': 0.9560497815148686, 'average': 0.7919029476890821, 'sample_size': 447}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7921174829624118, 'median': 0.7868223844753969, 'mode': 0.9560497815148686, 'average': 0.7921174829624118, 'sample_size': 448}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7922256511302997, 'median': 0.7868223844753969, 'mode': 0.9560497815148686, 'average': 0.7922256511302997, 'sample_size': 449}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7922741402867882, 'median': 0.7876843262085198, 'mode': 0.9560497815148686, 'average': 0.7922741402867882, 'sample_size': 450}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7924608327444834, 'median': 0.7885462679416428, 'mode': 0.9560497815148686, 'average': 0.7924608327444834, 'sample_size': 451}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7924331643849032, 'median': 0.7876843262085198, 'mode': 0.9560497815148686, 'average': 0.7924331643849032, 'sample_size': 452}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7925301195769386, 'median': 0.7885462679416428, 'mode': 0.9560497815148686, 'average': 0.7925301195769386, 'sample_size': 453}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7926560769922636, 'median': 0.7891766076375784, 'mode': 0.9560497815148686, 'average': 0.7926560769922636, 'sample_size': 454}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7927521160898124, 'median': 0.7898069473335139, 'mode': 0.9560497815148686, 'average': 0.7927521160898124, 'sample_size': 455}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7928572320421243, 'median': 0.7898069473335139, 'mode': 0.9560497815148686, 'average': 0.7928572320421243, 'sample_size': 456}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.792952410673054, 'median': 0.7898069473335139, 'mode': 0.9560497815148686, 'average': 0.792952410673054, 'sample_size': 457}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7929223635649577, 'median': 0.7898069473335139, 'mode': 0.9560497815148686, 'average': 0.7929223635649577, 'sample_size': 458}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7923795642101206, 'median': 0.7898069473335139, 'mode': 0.9560497815148686, 'average': 0.7923795642101206, 'sample_size': 459}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7923439195185918, 'median': 0.7891766076375784, 'mode': 0.9560497815148686, 'average': 0.7923439195185918, 'sample_size': 460}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7925658886128525, 'median': 0.7898069473335139, 'mode': 0.9560497815148686, 'average': 0.7925658886128525, 'sample_size': 461}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7923711661043005, 'median': 0.7891766076375784, 'mode': 0.9560497815148686, 'average': 0.7923711661043005, 'sample_size': 462}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7924319810172792, 'median': 0.7898069473335139, 'mode': 0.9560497815148686, 'average': 0.7924319810172792, 'sample_size': 463}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7925266402529682, 'median': 0.7898069473335139, 'mode': 0.9560497815148686, 'average': 0.7925266402529682, 'sample_size': 464}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7926496255129284, 'median': 0.7898069473335139, 'mode': 0.9560497815148686, 'average': 0.7926496255129284, 'sample_size': 465}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7927527056949694, 'median': 0.7898069473335139, 'mode': 0.9560497815148686, 'average': 0.7927527056949694, 'sample_size': 466}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7928746801712853, 'median': 0.7898069473335139, 'mode': 0.9560497815148686, 'average': 0.7928746801712853, 'sample_size': 467}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7929768389537057, 'median': 0.7898069473335139, 'mode': 0.9560497815148686, 'average': 0.7929768389537057, 'sample_size': 468}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7930978153869269, 'median': 0.7898069473335139, 'mode': 0.9560497815148686, 'average': 0.7930978153869269, 'sample_size': 469}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7927083021543317, 'median': 0.7898069473335139, 'mode': 0.9560497815148686, 'average': 0.7927083021543317, 'sample_size': 470}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7929854054783696, 'median': 0.7898069473335139, 'mode': 0.9560497815148686, 'average': 0.7929854054783696, 'sample_size': 471}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7931808374784944, 'median': 0.7898069473335139, 'mode': 0.9560497815148686, 'average': 0.7931808374784944, 'sample_size': 472}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7934494449748585, 'median': 0.7898069473335139, 'mode': 0.9560497815148686, 'average': 0.7934494449748585, 'sample_size': 473}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7932655523777702, 'median': 0.7898069473335139, 'mode': 0.9560497815148686, 'average': 0.7932655523777702, 'sample_size': 474}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7935139373269995, 'median': 0.7898069473335139, 'mode': 0.9560497815148686, 'average': 0.7935139373269995, 'sample_size': 475}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7938264120945594, 'median': 0.7898069473335139, 'mode': 0.9560497815148686, 'average': 0.7938264120945594, 'sample_size': 476}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7936641202569871, 'median': 0.7898069473335139, 'mode': 0.9560497815148686, 'average': 0.7936641202569871, 'sample_size': 477}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.793449408999411, 'median': 0.7898069473335139, 'mode': 0.9560497815148686, 'average': 0.793449408999411, 'sample_size': 478}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7937140912003698, 'median': 0.7898069473335139, 'mode': 0.9560497815148686, 'average': 0.7937140912003698, 'sample_size': 479}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7939047479052387, 'median': 0.7898069473335139, 'mode': 0.9560497815148686, 'average': 0.7939047479052387, 'sample_size': 480}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7941673829059733, 'median': 0.7898069473335139, 'mode': 0.9560497815148686, 'average': 0.7941673829059733, 'sample_size': 481}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7944102895872093, 'median': 0.7903552247268815, 'mode': 0.9560497815148686, 'average': 0.7944102895872093, 'sample_size': 482}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7946707904022642, 'median': 0.7909035021202491, 'mode': 0.9560497815148686, 'average': 0.7946707904022642, 'sample_size': 483}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7944691256116261, 'median': 0.7903552247268815, 'mode': 0.9560497815148686, 'average': 0.7944691256116261, 'sample_size': 484}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7938591088023645, 'median': 0.7898069473335139, 'mode': 0.9560497815148686, 'average': 0.7938591088023645, 'sample_size': 485}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7936226278773424, 'median': 0.7898069473335139, 'mode': 0.9560497815148686, 'average': 0.7936226278773424, 'sample_size': 486}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7934895643285372, 'median': 0.7898069473335139, 'mode': 0.9560497815148686, 'average': 0.7934895643285372, 'sample_size': 487}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7930465671298483, 'median': 0.7898069473335139, 'mode': 0.9560497815148686, 'average': 0.7930465671298483, 'sample_size': 488}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7933127785831126, 'median': 0.7898069473335139, 'mode': 0.9560497815148686, 'average': 0.7933127785831126, 'sample_size': 489}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.793571797776328, 'median': 0.7898069473335139, 'mode': 0.9560497815148686, 'average': 0.793571797776328, 'sample_size': 490}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7937584729530308, 'median': 0.7898069473335139, 'mode': 0.9560497815148686, 'average': 0.7937584729530308, 'sample_size': 491}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7939972736243899, 'median': 0.7903552247268815, 'mode': 0.9560497815148686, 'average': 0.7939972736243899, 'sample_size': 492}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7941823284639699, 'median': 0.7909035021202491, 'mode': 0.9560497815148686, 'average': 0.7941823284639699, 'sample_size': 493}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7944193043238844, 'median': 0.7910859742060368, 'mode': 0.9560497815148686, 'average': 0.7944193043238844, 'sample_size': 494}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7946027588798712, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.7946027588798712, 'sample_size': 495}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7943606874679838, 'median': 0.7910859742060368, 'mode': 0.9560497815148686, 'average': 0.7943606874679838, 'sample_size': 496}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7941621884578769, 'median': 0.7909035021202491, 'mode': 0.9560497815148686, 'average': 0.7941621884578769, 'sample_size': 497}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.793918013357431, 'median': 0.7903552247268815, 'mode': 0.9560497815148686, 'average': 0.793918013357431, 'sample_size': 498}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7938751903049501, 'median': 0.7898069473335139, 'mode': 0.9560497815148686, 'average': 0.7938751903049501, 'sample_size': 499}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7936824766828989, 'median': 0.7898069473335139, 'mode': 0.9560497815148686, 'average': 0.7936824766828989, 'sample_size': 500}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7933976540198947, 'median': 0.7898069473335139, 'mode': 0.9560497815148686, 'average': 0.7933976540198947, 'sample_size': 501}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7933961071617524, 'median': 0.7898069473335139, 'mode': 0.9560497815148686, 'average': 0.7933961071617524, 'sample_size': 502}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7932295569218469, 'median': 0.7898069473335139, 'mode': 0.9560497815148686, 'average': 0.7932295569218469, 'sample_size': 503}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7929901391272318, 'median': 0.7898069473335139, 'mode': 0.9560497815148686, 'average': 0.7929901391272318, 'sample_size': 504}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7927974986130092, 'median': 0.7898069473335139, 'mode': 0.9560497815148686, 'average': 0.7927974986130092, 'sample_size': 505}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7925598810039634, 'median': 0.7898069473335139, 'mode': 0.9560497815148686, 'average': 0.7925598810039634, 'sample_size': 506}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7923724224206802, 'median': 0.7898069473335139, 'mode': 0.9560497815148686, 'average': 0.7923724224206802, 'sample_size': 507}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7921365770781903, 'median': 0.7898069473335139, 'mode': 0.9560497815148686, 'average': 0.7921365770781903, 'sample_size': 508}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.791956624739986, 'median': 0.7898069473335139, 'mode': 0.9560497815148686, 'average': 0.791956624739986, 'sample_size': 509}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.791887066186688, 'median': 0.7898069473335139, 'mode': 0.9560497815148686, 'average': 0.791887066186688, 'sample_size': 510}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7916651359044706, 'median': 0.7898069473335139, 'mode': 0.9560497815148686, 'average': 0.7916651359044706, 'sample_size': 511}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7916259972649766, 'median': 0.7891766076375784, 'mode': 0.9560497815148686, 'average': 0.7916259972649766, 'sample_size': 512}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7918698002415214, 'median': 0.7898069473335139, 'mode': 0.9560497815148686, 'average': 0.7918698002415214, 'sample_size': 513}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7916415230787631, 'median': 0.7891766076375784, 'mode': 0.9560497815148686, 'average': 0.7916415230787631, 'sample_size': 514}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7914103026231457, 'median': 0.7885462679416428, 'mode': 0.9560497815148686, 'average': 0.7914103026231457, 'sample_size': 515}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7912248304852032, 'median': 0.7876843262085198, 'mode': 0.9560497815148686, 'average': 0.7912248304852032, 'sample_size': 516}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7910435800960237, 'median': 0.7868223844753969, 'mode': 0.9560497815148686, 'average': 0.7910435800960237, 'sample_size': 517}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7908595320252685, 'median': 0.7868223844753969, 'mode': 0.9560497815148686, 'average': 0.7908595320252685, 'sample_size': 518}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.79067968394676, 'median': 0.7868223844753969, 'mode': 0.9560497815148686, 'average': 0.79067968394676, 'sample_size': 519}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.790497043553487, 'median': 0.7868223844753969, 'mode': 0.9560497815148686, 'average': 0.790497043553487, 'sample_size': 520}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7908148031273092, 'median': 0.7868223844753969, 'mode': 0.9560497815148686, 'average': 0.7908148031273092, 'sample_size': 521}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7911522367241555, 'median': 0.7868223844753969, 'mode': 0.9560497815148686, 'average': 0.7911522367241555, 'sample_size': 522}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7911186594566418, 'median': 0.7868223844753969, 'mode': 0.9560497815148686, 'average': 0.7911186594566418, 'sample_size': 523}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7914509937096318, 'median': 0.7868223844753969, 'mode': 0.9560497815148686, 'average': 0.7914509937096318, 'sample_size': 524}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7917869723079184, 'median': 0.7868223844753969, 'mode': 0.9560497815148686, 'average': 0.7917869723079184, 'sample_size': 525}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7917538943256472, 'median': 0.7868223844753969, 'mode': 0.9560497815148686, 'average': 0.7917538943256472, 'sample_size': 526}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7916135601940394, 'median': 0.7868223844753969, 'mode': 0.9560497815148686, 'average': 0.7916135601940394, 'sample_size': 527}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7919456465207193, 'median': 0.7868223844753969, 'mode': 0.9560497815148686, 'average': 0.7919456465207193, 'sample_size': 528}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.792255862276852, 'median': 0.7868223844753969, 'mode': 0.9560497815148686, 'average': 0.792255862276852, 'sample_size': 529}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7925854835568599, 'median': 0.7876843262085198, 'mode': 0.9560497815148686, 'average': 0.7925854835568599, 'sample_size': 530}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7929106743750642, 'median': 0.7885462679416428, 'mode': 0.9560497815148686, 'average': 0.7929106743750642, 'sample_size': 531}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7932378256275191, 'median': 0.7891766076375784, 'mode': 0.9560497815148686, 'average': 0.7932378256275191, 'sample_size': 532}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.793118336531131, 'median': 0.7885462679416428, 'mode': 0.9560497815148686, 'average': 0.793118336531131, 'sample_size': 533}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7926100702518979, 'median': 0.7876843262085198, 'mode': 0.9560497815148686, 'average': 0.7926100702518979, 'sample_size': 534}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7924261106246148, 'median': 0.7868223844753969, 'mode': 0.9560497815148686, 'average': 0.7924261106246148, 'sample_size': 535}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7924022888652217, 'median': 0.7868223844753969, 'mode': 0.9560497815148686, 'average': 0.7924022888652217, 'sample_size': 536}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7921379641123618, 'median': 0.7868223844753969, 'mode': 0.9560497815148686, 'average': 0.7921379641123618, 'sample_size': 537}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.792524324773863, 'median': 0.7868223844753969, 'mode': 0.9560497815148686, 'average': 0.792524324773863, 'sample_size': 538}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7928479440983661, 'median': 0.7868223844753969, 'mode': 0.9560497815148686, 'average': 0.7928479440983661, 'sample_size': 539}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7931501697232115, 'median': 0.7876843262085198, 'mode': 0.9560497815148686, 'average': 0.7931501697232115, 'sample_size': 540}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7934683058383688, 'median': 0.7885462679416428, 'mode': 0.9560497815148686, 'average': 0.7934683058383688, 'sample_size': 541}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7937682716606502, 'median': 0.7891766076375784, 'mode': 0.9560497815148686, 'average': 0.7937682716606502, 'sample_size': 542}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7940840976944674, 'median': 0.7898069473335139, 'mode': 0.9560497815148686, 'average': 0.7940840976944674, 'sample_size': 543}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.794381828730902, 'median': 0.7898069473335139, 'mode': 0.9560497815148686, 'average': 0.794381828730902, 'sample_size': 544}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7946691200942798, 'median': 0.7898069473335139, 'mode': 0.9560497815148686, 'average': 0.7946691200942798, 'sample_size': 545}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7947016044345483, 'median': 0.7898069473335139, 'mode': 0.9560497815148686, 'average': 0.7947016044345483, 'sample_size': 546}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7950251013922272, 'median': 0.7898069473335139, 'mode': 0.9560497815148686, 'average': 0.7950251013922272, 'sample_size': 547}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7952787078518619, 'median': 0.7898069473335139, 'mode': 0.9560497815148686, 'average': 0.7952787078518619, 'sample_size': 548}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.79528252061979, 'median': 0.7898069473335139, 'mode': 0.9560497815148686, 'average': 0.79528252061979, 'sample_size': 549}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7951467134077423, 'median': 0.7898069473335139, 'mode': 0.9560497815148686, 'average': 0.7951467134077423, 'sample_size': 550}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7954294881960619, 'median': 0.7898069473335139, 'mode': 0.9560497815148686, 'average': 0.7954294881960619, 'sample_size': 551}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7958000869493298, 'median': 0.7898069473335139, 'mode': 0.9560497815148686, 'average': 0.7958000869493298, 'sample_size': 552}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7960806575367123, 'median': 0.7898069473335139, 'mode': 0.9560497815148686, 'average': 0.7960806575367123, 'sample_size': 553}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7963975777221781, 'median': 0.7898069473335139, 'mode': 0.9560497815148686, 'average': 0.7963975777221781, 'sample_size': 554}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7966760606844299, 'median': 0.7898069473335139, 'mode': 0.9560497815148686, 'average': 0.7966760606844299, 'sample_size': 555}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7965757167260771, 'median': 0.7898069473335139, 'mode': 0.9560497815148686, 'average': 0.7965757167260771, 'sample_size': 556}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7960911109370413, 'median': 0.7898069473335139, 'mode': 0.9560497815148686, 'average': 0.7960911109370413, 'sample_size': 557}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7959651548697061, 'median': 0.7898069473335139, 'mode': 0.9560497815148686, 'average': 0.7959651548697061, 'sample_size': 558}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.795999531820449, 'median': 0.7898069473335139, 'mode': 0.9560497815148686, 'average': 0.795999531820449, 'sample_size': 559}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7957706051753579, 'median': 0.7898069473335139, 'mode': 0.9560497815148686, 'average': 0.7957706051753579, 'sample_size': 560}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7960563078069791, 'median': 0.7898069473335139, 'mode': 0.9560497815148686, 'average': 0.7960563078069791, 'sample_size': 561}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7963319293620766, 'median': 0.7898069473335139, 'mode': 0.9560497815148686, 'average': 0.7963319293620766, 'sample_size': 562}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7966936843720908, 'median': 0.7898069473335139, 'mode': 0.9560497815148686, 'average': 0.7966936843720908, 'sample_size': 563}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.797003898478319, 'median': 0.7903552247268815, 'mode': 0.9560497815148686, 'average': 0.797003898478319, 'sample_size': 564}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7973631836137556, 'median': 0.7909035021202491, 'mode': 0.9560497815148686, 'average': 0.7973631836137556, 'sample_size': 565}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7976711186962133, 'median': 0.7910859742060368, 'mode': 0.9560497815148686, 'average': 0.7976711186962133, 'sample_size': 566}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7980279597567138, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.7980279597567138, 'sample_size': 567}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.797991027722932, 'median': 0.7910859742060368, 'mode': 0.9560497815148686, 'average': 0.797991027722932, 'sample_size': 568}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7982970000515873, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.7982970000515873, 'sample_size': 569}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7986016626377225, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.7986016626377225, 'sample_size': 570}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7985568686540062, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.7985568686540062, 'sample_size': 571}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7984378214577776, 'median': 0.7910859742060368, 'mode': 0.9560497815148686, 'average': 0.7984378214577776, 'sample_size': 572}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7987895879124761, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.7987895879124761, 'sample_size': 573}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7990546855324401, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.7990546855324401, 'sample_size': 574}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7994041556445576, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.7994041556445576, 'sample_size': 575}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7997039562124103, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.7997039562124103, 'sample_size': 576}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8000510897371722, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8000510897371722, 'sample_size': 577}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7999343350274724, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.7999343350274724, 'sample_size': 578}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7994408575554575, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.7994408575554575, 'sample_size': 579}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.79926807582636, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.79926807582636, 'sample_size': 580}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7992536789697229, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.7992536789697229, 'sample_size': 581}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.798998962237489, 'median': 0.7910859742060368, 'mode': 0.9560497815148686, 'average': 0.798998962237489, 'sample_size': 582}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7992870517373921, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.7992870517373921, 'sample_size': 583}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7996307382926364, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.7996307382926364, 'sample_size': 584}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.7998894133071306, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.7998894133071306, 'sample_size': 585}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8001832697395892, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8001832697395892, 'sample_size': 586}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8004401221280597, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8004401221280597, 'sample_size': 587}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8007320424692158, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8007320424692158, 'sample_size': 588}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.800987090990952, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.800987090990952, 'sample_size': 589}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.800961052542514, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.800961052542514, 'sample_size': 590}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.800874138022752, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.800874138022752, 'sample_size': 591}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8011520364660301, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8011520364660301, 'sample_size': 592}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8012841057488197, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8012841057488197, 'sample_size': 593}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8012433085414457, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8012433085414457, 'sample_size': 594}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8012620686445372, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8012620686445372, 'sample_size': 595}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8012214453155508, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8012214453155508, 'sample_size': 596}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.801195319622246, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.801195319622246, 'sample_size': 597}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8011549437776747, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8011549437776747, 'sample_size': 598}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.801319367273343, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.801319367273343, 'sample_size': 599}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8008795207243595, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8008795207243595, 'sample_size': 600}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8009916312988623, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8009916312988623, 'sample_size': 601}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8012898480525671, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8012898480525671, 'sample_size': 602}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8011262859765949, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8011262859765949, 'sample_size': 603}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8010806982942072, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8010806982942072, 'sample_size': 604}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8010409790649088, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8010409790649088, 'sample_size': 605}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8010597325151002, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8010597325151002, 'sample_size': 606}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8010343036417847, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8010343036417847, 'sample_size': 607}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8010530063823097, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8010530063823097, 'sample_size': 608}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8010276720638043, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8010276720638043, 'sample_size': 609}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8010463243553078, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8010463243553078, 'sample_size': 610}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8012972078602183, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8012972078602183, 'sample_size': 611}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8012805781715033, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8012805781715033, 'sample_size': 612}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8011578022996855, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8011578022996855, 'sample_size': 613}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.801436192332956, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.801436192332956, 'sample_size': 614}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8017129699719022, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8017129699719022, 'sample_size': 615}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8019895548952073, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8019895548952073, 'sample_size': 616}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8023104794415684, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8023104794415684, 'sample_size': 617}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8025852024242321, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8025852024242321, 'sample_size': 618}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.80248220194831, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.80248220194831, 'sample_size': 619}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8020352639724876, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8020352639724876, 'sample_size': 620}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8018868001912973, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8018868001912973, 'sample_size': 621}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8018986427967228, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8018986427967228, 'sample_size': 622}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8016869904581312, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8016869904581312, 'sample_size': 623}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8019491295888448, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8019491295888448, 'sample_size': 624}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8022213538338671, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8022213538338671, 'sample_size': 625}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8024920137163765, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8024920137163765, 'sample_size': 626}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8028070184791893, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8028070184791893, 'sample_size': 627}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8030758838005359, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8030758838005359, 'sample_size': 628}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8033889587070533, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8033889587070533, 'sample_size': 629}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8036560467730498, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8036560467730498, 'sample_size': 630}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8035656240755329, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8035656240755329, 'sample_size': 631}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8034152678574268, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8034152678574268, 'sample_size': 632}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8036815228436687, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8036815228436687, 'sample_size': 633}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8038870747654803, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8038870747654803, 'sample_size': 634}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8041517481503354, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8041517481503354, 'sample_size': 635}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8043878871404381, 'median': 0.7919447887621145, 'mode': 0.9560497815148686, 'average': 0.8043878871404381, 'sample_size': 636}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8046509433209846, 'median': 0.7926211312324043, 'mode': 0.9560497815148686, 'average': 0.8046509433209846, 'sample_size': 637}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8045063654318603, 'median': 0.7919447887621145, 'mode': 0.9560497815148686, 'average': 0.8045063654318603, 'sample_size': 638}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8040452829226704, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8040452829226704, 'sample_size': 639}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8038571179984032, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8038571179984032, 'sample_size': 640}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.803788421378433, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.803788421378433, 'sample_size': 641}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8035030798071406, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8035030798071406, 'sample_size': 642}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8037586578444701, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8037586578444701, 'sample_size': 643}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8040198317828308, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8040198317828308, 'sample_size': 644}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.804221353658008, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.804221353658008, 'sample_size': 645}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8044537294973232, 'median': 0.7919447887621145, 'mode': 0.9560497815148686, 'average': 0.8044537294973232, 'sample_size': 646}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8046539577999118, 'median': 0.7926211312324043, 'mode': 0.9560497815148686, 'average': 0.8046539577999118, 'sample_size': 647}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8048849488308619, 'median': 0.792741761323311, 'mode': 0.9560497815148686, 'average': 0.8048849488308619, 'sample_size': 648}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8050838956605094, 'median': 0.7928623914142177, 'mode': 0.9560497815148686, 'average': 0.8050838956605094, 'sample_size': 649}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8051998100961324, 'median': 0.7928623914142177, 'mode': 0.9560497815148686, 'average': 0.8051998100961324, 'sample_size': 650}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8051503853462699, 'median': 0.7928623914142177, 'mode': 0.9560497815148686, 'average': 0.8051503853462699, 'sample_size': 651}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8051384551807762, 'median': 0.7928623914142177, 'mode': 0.9560497815148686, 'average': 0.8051384551807762, 'sample_size': 652}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8050892757669246, 'median': 0.7928623914142177, 'mode': 0.9560497815148686, 'average': 0.8050892757669246, 'sample_size': 653}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8050679157708996, 'median': 0.792741761323311, 'mode': 0.9560497815148686, 'average': 0.8050679157708996, 'sample_size': 654}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8050189942169529, 'median': 0.7926211312324043, 'mode': 0.9560497815148686, 'average': 0.8050189942169529, 'sample_size': 655}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8051294095180471, 'median': 0.792741761323311, 'mode': 0.9560497815148686, 'average': 0.8051294095180471, 'sample_size': 656}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8047625961673663, 'median': 0.7926211312324043, 'mode': 0.9560497815148686, 'average': 0.8047625961673663, 'sample_size': 657}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8048203495664975, 'median': 0.792741761323311, 'mode': 0.9560497815148686, 'average': 0.8048203495664975, 'sample_size': 658}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8050694609734463, 'median': 0.7928623914142177, 'mode': 0.9560497815148686, 'average': 0.8050694609734463, 'sample_size': 659}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8049381758108497, 'median': 0.792741761323311, 'mode': 0.9560497815148686, 'average': 0.8049381758108497, 'sample_size': 660}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8048919576229863, 'median': 0.7926211312324043, 'mode': 0.9560497815148686, 'average': 0.8048919576229863, 'sample_size': 661}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8048438191642442, 'median': 0.7919447887621145, 'mode': 0.9560497815148686, 'average': 0.8048438191642442, 'sample_size': 662}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8048325493275627, 'median': 0.7926211312324043, 'mode': 0.9560497815148686, 'average': 0.8048325493275627, 'sample_size': 663}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8048118976544287, 'median': 0.7919447887621145, 'mode': 0.9560497815148686, 'average': 0.8048118976544287, 'sample_size': 664}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8048007097142632, 'median': 0.7926211312324043, 'mode': 0.9560497815148686, 'average': 0.8048007097142632, 'sample_size': 665}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8047801678653929, 'median': 0.7919447887621145, 'mode': 0.9560497815148686, 'average': 0.8047801678653929, 'sample_size': 666}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8047690610431723, 'median': 0.7926211312324043, 'mode': 0.9560497815148686, 'average': 0.8047690610431723, 'sample_size': 667}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8046578227368372, 'median': 0.7919447887621145, 'mode': 0.9560497815148686, 'average': 0.8046578227368372, 'sample_size': 668}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8045321586579982, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8045321586579982, 'sample_size': 669}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8044216059919583, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8044216059919583, 'sample_size': 670}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8043047615251256, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8043047615251256, 'sample_size': 671}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8041948762734682, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8041948762734682, 'sample_size': 672}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8044158032805356, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8044158032805356, 'sample_size': 673}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8040141304105126, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8040141304105126, 'sample_size': 674}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8042083890386914, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8042083890386914, 'sample_size': 675}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8043207867541788, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8043207867541788, 'sample_size': 676}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.804084920337808, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.804084920337808, 'sample_size': 677}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8039576532089443, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8039576532089443, 'sample_size': 678}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8038494120001113, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8038494120001113, 'sample_size': 679}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8037269695618664, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8037269695618664, 'sample_size': 680}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8036128608969403, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8036128608969403, 'sample_size': 681}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8034911243765542, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8034911243765542, 'sample_size': 682}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8033776951589416, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8033776951589416, 'sample_size': 683}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.803256658402852, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.803256658402852, 'sample_size': 684}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8034722773274782, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8034722773274782, 'sample_size': 685}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8037587608882253, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8037587608882253, 'sample_size': 686}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8040037834818783, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8040037834818783, 'sample_size': 687}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8042886617035616, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8042886617035616, 'sample_size': 688}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8041845662112933, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8041845662112933, 'sample_size': 689}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8037643144903072, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8037643144903072, 'sample_size': 690}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8036130310462963, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8036130310462963, 'sample_size': 691}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.803594664675016, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.803594664675016, 'sample_size': 692}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.803374482678096, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.803374482678096, 'sample_size': 693}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8036101896781003, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8036101896781003, 'sample_size': 694}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8038927649447505, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8038927649447505, 'sample_size': 695}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8041040621528355, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8041040621528355, 'sample_size': 696}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8043450739470606, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8043450739470606, 'sample_size': 697}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8045551177118526, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8045551177118526, 'sample_size': 698}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8047947946288997, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8047947946288997, 'sample_size': 699}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8050035958105325, 'median': 0.7912684462918246, 'mode': 0.9560497815148686, 'average': 0.8050035958105325, 'sample_size': 700}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8052118012683944, 'median': 0.7912684462918246, 'mode': 0.9509556217718045, 'average': 0.8052118012683944, 'sample_size': 701}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8054488990447711, 'median': 0.7912684462918246, 'mode': 0.9509556217718045, 'average': 0.8054488990447711, 'sample_size': 702}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8056558787357059, 'median': 0.7912684462918246, 'mode': 0.9509556217718045, 'average': 0.8056558787357059, 'sample_size': 703}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8055638743906838, 'median': 0.7912684462918246, 'mode': 0.9509556217718045, 'average': 0.8055638743906838, 'sample_size': 704}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8051682522883328, 'median': 0.7912684462918246, 'mode': 0.9509556217718045, 'average': 0.8051682522883328, 'sample_size': 705}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8050558434683267, 'median': 0.7912684462918246, 'mode': 0.9509556217718045, 'average': 0.8050558434683267, 'sample_size': 706}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8050701659957193, 'median': 0.7912684462918246, 'mode': 0.9509556217718045, 'average': 0.8050701659957193, 'sample_size': 707}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8048762824428574, 'median': 0.7912684462918246, 'mode': 0.9509556217718045, 'average': 0.8048762824428574, 'sample_size': 708}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8050895031749759, 'median': 0.7912684462918246, 'mode': 0.9509556217718045, 'average': 0.8050895031749759, 'sample_size': 709}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8052949484124361, 'median': 0.7912684462918246, 'mode': 0.9509556217718045, 'average': 0.8052949484124361, 'sample_size': 710}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8055687951797885, 'median': 0.7912684462918246, 'mode': 0.9509556217718045, 'average': 0.8055687951797885, 'sample_size': 711}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8058020615352732, 'median': 0.7919447887621145, 'mode': 0.9509556217718045, 'average': 0.8058020615352732, 'sample_size': 712}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8060744289103992, 'median': 0.7926211312324043, 'mode': 0.9509556217718045, 'average': 0.8060744289103992, 'sample_size': 713}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8063063336882343, 'median': 0.792741761323311, 'mode': 0.9509556217718045, 'average': 0.8063063336882343, 'sample_size': 714}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8065772339208382, 'median': 0.7928623914142177, 'mode': 0.9509556217718045, 'average': 0.8065772339208382, 'sample_size': 715}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8068083960001776, 'median': 0.7928623914142177, 'mode': 0.9509556217718045, 'average': 0.8068083960001776, 'sample_size': 716}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8070778403572206, 'median': 0.7928623914142177, 'mode': 0.9509556217718045, 'average': 0.8070778403572206, 'sample_size': 717}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8069740646290497, 'median': 0.7928623914142177, 'mode': 0.9509556217718045, 'average': 0.8069740646290497, 'sample_size': 718}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8065668835638228, 'median': 0.7928623914142177, 'mode': 0.9509556217718045, 'average': 0.8065668835638228, 'sample_size': 719}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.806417801023705, 'median': 0.792741761323311, 'mode': 0.9509556217718045, 'average': 0.806417801023705, 'sample_size': 720}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.806396283272105, 'median': 0.7926211312324043, 'mode': 0.9509556217718045, 'average': 0.806396283272105, 'sample_size': 721}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.80618106479224, 'median': 0.7919447887621145, 'mode': 0.9509556217718045, 'average': 0.80618106479224, 'sample_size': 722}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8064034355749354, 'median': 0.7926211312324043, 'mode': 0.9509556217718045, 'average': 0.8064034355749354, 'sample_size': 723}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8066708341445833, 'median': 0.792741761323311, 'mode': 0.9509556217718045, 'average': 0.8066708341445833, 'sample_size': 724}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8068698476447588, 'median': 0.7928623914142177, 'mode': 0.9509556217718045, 'average': 0.8068698476447588, 'sample_size': 725}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.807097422624212, 'median': 0.7928623914142177, 'mode': 0.9509556217718045, 'average': 0.807097422624212, 'sample_size': 726}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8072953018527508, 'median': 0.7928623914142177, 'mode': 0.9509556217718045, 'average': 0.8072953018527508, 'sample_size': 727}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8075216672110955, 'median': 0.7928623914142177, 'mode': 0.9509556217718045, 'average': 0.8075216672110955, 'sample_size': 728}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8077184216069264, 'median': 0.7928623914142177, 'mode': 0.9509556217718045, 'average': 0.8077184216069264, 'sample_size': 729}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8079435871701058, 'median': 0.7928623914142177, 'mode': 0.9509556217718045, 'average': 0.8079435871701058, 'sample_size': 730}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8078490376771623, 'median': 0.7928623914142177, 'mode': 0.9509556217718045, 'average': 0.8078490376771623, 'sample_size': 731}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8074631519111259, 'median': 0.7928623914142177, 'mode': 0.9509556217718045, 'average': 0.8074631519111259, 'sample_size': 732}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8073299678783048, 'median': 0.7928623914142177, 'mode': 0.9509556217718045, 'average': 0.8073299678783048, 'sample_size': 733}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8073325876778792, 'median': 0.7928623914142177, 'mode': 0.9509556217718045, 'average': 0.8073325876778792, 'sample_size': 734}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8071457940019285, 'median': 0.7928623914142177, 'mode': 0.9509556217718045, 'average': 0.8071457940019285, 'sample_size': 735}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8073606255427187, 'median': 0.7928623914142177, 'mode': 0.9509556217718045, 'average': 0.8073606255427187, 'sample_size': 736}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8075841379676646, 'median': 0.7928623914142177, 'mode': 0.9509556217718045, 'average': 0.8075841379676646, 'sample_size': 737}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.807806455450479, 'median': 0.7928623914142177, 'mode': 0.9509556217718045, 'average': 0.807806455450479, 'sample_size': 738}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8080665279058912, 'median': 0.7928623914142177, 'mode': 0.9509556217718045, 'average': 0.8080665279058912, 'sample_size': 739}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8082875926523492, 'median': 0.7936309021371175, 'mode': 0.9509556217718045, 'average': 0.8082875926523492, 'sample_size': 740}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8085463138498494, 'median': 0.7943994128600174, 'mode': 0.9509556217718045, 'average': 0.8085463138498494, 'sample_size': 741}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8087661361226729, 'median': 0.7943994128600174, 'mode': 0.9509556217718045, 'average': 0.8087661361226729, 'sample_size': 742}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8086635799065328, 'median': 0.7943994128600174, 'mode': 0.9509556217718045, 'average': 0.8086635799065328, 'sample_size': 743}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.808267810146888, 'median': 0.7936309021371175, 'mode': 0.9509556217718045, 'average': 0.808267810146888, 'sample_size': 744}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8081214472536424, 'median': 0.7928623914142177, 'mode': 0.9509556217718045, 'average': 0.8081214472536424, 'sample_size': 745}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8080983668982358, 'median': 0.7928623914142177, 'mode': 0.9509556217718045, 'average': 0.8080983668982358, 'sample_size': 746}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8078880726196699, 'median': 0.7928623914142177, 'mode': 0.9509556217718045, 'average': 0.8078880726196699, 'sample_size': 747}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8081007291277733, 'median': 0.7928623914142177, 'mode': 0.9509556217718045, 'average': 0.8081007291277733, 'sample_size': 748}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8083569364320086, 'median': 0.7928623914142177, 'mode': 0.9509556217718045, 'average': 0.8083569364320086, 'sample_size': 749}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8085470680124618, 'median': 0.7936309021371175, 'mode': 0.9509556217718045, 'average': 0.8085470680124618, 'sample_size': 750}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8087648339441732, 'median': 0.7943994128600174, 'mode': 0.9509556217718045, 'average': 0.8087648339441732, 'sample_size': 751}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8089539174386248, 'median': 0.7943994128600174, 'mode': 0.9509556217718045, 'average': 0.8089539174386248, 'sample_size': 752}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8091705646700845, 'median': 0.7943994128600174, 'mode': 0.9509556217718045, 'average': 0.8091705646700845, 'sample_size': 753}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8093586085123946, 'median': 0.7943994128600174, 'mode': 0.9509556217718045, 'average': 0.8093586085123946, 'sample_size': 754}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8089800577435441, 'median': 0.7943994128600174, 'mode': 0.9509556217718045, 'average': 0.8089800577435441, 'sample_size': 755}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8091611243939273, 'median': 0.7943994128600174, 'mode': 0.9509556217718045, 'average': 0.8091611243939273, 'sample_size': 756}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.809281501427497, 'median': 0.7943994128600174, 'mode': 0.9509556217718045, 'average': 0.809281501427497, 'sample_size': 757}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.809051417015437, 'median': 0.7943994128600174, 'mode': 0.9509556217718045, 'average': 0.809051417015437, 'sample_size': 758}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8089466722463161, 'median': 0.7943994128600174, 'mode': 0.9509556217718045, 'average': 0.8089466722463161, 'sample_size': 759}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.808846172503269, 'median': 0.7943994128600174, 'mode': 0.9509556217718045, 'average': 0.808846172503269, 'sample_size': 760}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.808756867177825, 'median': 0.7943994128600174, 'mode': 0.9509556217718045, 'average': 0.808756867177825, 'sample_size': 761}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8086650968899649, 'median': 0.7936309021371175, 'mode': 0.9509556217718045, 'average': 0.8086650968899649, 'sample_size': 762}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8085762629750898, 'median': 0.7928623914142177, 'mode': 0.9509556217718045, 'average': 0.8085762629750898, 'sample_size': 763}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8084849693165209, 'median': 0.7928623914142177, 'mode': 0.9509556217718045, 'average': 0.8084849693165209, 'sample_size': 764}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8083966031080552, 'median': 0.7928623914142177, 'mode': 0.9509556217718045, 'average': 0.8083966031080552, 'sample_size': 765}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8080193786163203, 'median': 0.7928623914142177, 'mode': 0.9509556217718045, 'average': 0.8080193786163203, 'sample_size': 766}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8076699981208633, 'median': 0.7928623914142177, 'mode': 0.9509556217718045, 'average': 0.8076699981208633, 'sample_size': 767}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8076003558776197, 'median': 0.7928623914142177, 'mode': 0.9509556217718045, 'average': 0.8076003558776197, 'sample_size': 768}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8072285792684429, 'median': 0.7928623914142177, 'mode': 0.9509556217718045, 'average': 0.8072285792684429, 'sample_size': 769}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8068480368002122, 'median': 0.792741761323311, 'mode': 0.9509556217718045, 'average': 0.8068480368002122, 'sample_size': 770}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.806484615601033, 'median': 0.7926211312324043, 'mode': 0.9509556217718045, 'average': 0.806484615601033, 'sample_size': 771}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8061204913022474, 'median': 0.7919447887621145, 'mode': 0.9509556217718045, 'average': 0.8061204913022474, 'sample_size': 772}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8057589515880571, 'median': 0.7912684462918246, 'mode': 0.9509556217718045, 'average': 0.8057589515880571, 'sample_size': 773}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8053967057293366, 'median': 0.7912684462918246, 'mode': 0.9509556217718045, 'average': 0.8053967057293366, 'sample_size': 774}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8050370329377287, 'median': 0.7912684462918246, 'mode': 0.9509556217718045, 'average': 0.8050370329377287, 'sample_size': 775}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8051210779407687, 'median': 0.7912684462918246, 'mode': 0.9509556217718045, 'average': 0.8051210779407687, 'sample_size': 776}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8048942573550135, 'median': 0.7912684462918246, 'mode': 0.9509556217718045, 'average': 0.8048942573550135, 'sample_size': 777}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8047519661111838, 'median': 0.7912684462918246, 'mode': 0.9509556217718045, 'average': 0.8047519661111838, 'sample_size': 778}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8046165046074196, 'median': 0.7912684462918246, 'mode': 0.9509556217718045, 'average': 0.8046165046074196, 'sample_size': 779}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8045154675827485, 'median': 0.7912684462918246, 'mode': 0.9509556217718045, 'average': 0.8045154675827485, 'sample_size': 780}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8043942432399454, 'median': 0.7912684462918246, 'mode': 0.9509556217718045, 'average': 0.8043942432399454, 'sample_size': 781}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8042937488436844, 'median': 0.7912684462918246, 'mode': 0.9509556217718045, 'average': 0.8042937488436844, 'sample_size': 782}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8041731173072983, 'median': 0.7912684462918246, 'mode': 0.9509556217718045, 'average': 0.8041731173072983, 'sample_size': 783}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8040731613226768, 'median': 0.7912684462918246, 'mode': 0.9509556217718045, 'average': 0.8040731613226768, 'sample_size': 784}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.803957102147687, 'median': 0.7912684462918246, 'mode': 0.9509556217718045, 'average': 0.803957102147687, 'sample_size': 785}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8039261868110994, 'median': 0.7912684462918246, 'mode': 0.9509556217718045, 'average': 0.8039261868110994, 'sample_size': 786}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8039096395624453, 'median': 0.7912684462918246, 'mode': 0.9509556217718045, 'average': 0.8039096395624453, 'sample_size': 787}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8039239444238319, 'median': 0.7912684462918246, 'mode': 0.9509556217718045, 'average': 0.8039239444238319, 'sample_size': 788}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8039306984876369, 'median': 0.7912684462918246, 'mode': 0.9509556217718045, 'average': 0.8039306984876369, 'sample_size': 789}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8039449404773172, 'median': 0.7912684462918246, 'mode': 0.9509556217718045, 'average': 0.8039449404773172, 'sample_size': 790}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.80395165092016, 'median': 0.7912684462918246, 'mode': 0.9509556217718045, 'average': 0.80395165092016, 'sample_size': 791}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8039658304901284, 'median': 0.7912684462918246, 'mode': 0.9509556217718045, 'average': 0.8039658304901284, 'sample_size': 792}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8037722542809094, 'median': 0.7912684462918246, 'mode': 0.9509556217718045, 'average': 0.8037722542809094, 'sample_size': 793}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8035798566568899, 'median': 0.7912684462918246, 'mode': 0.9509556217718045, 'average': 0.8035798566568899, 'sample_size': 794}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8034090651523772, 'median': 0.7912684462918246, 'mode': 0.9509556217718045, 'average': 0.8034090651523772, 'sample_size': 795}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8032415151155704, 'median': 0.7912684462918246, 'mode': 0.9509556217718045, 'average': 0.8032415151155704, 'sample_size': 796}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8030715767158888, 'median': 0.7912684462918246, 'mode': 0.9509556217718045, 'average': 0.8030715767158888, 'sample_size': 797}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8029048695218264, 'median': 0.7911941423292099, 'mode': 0.9509556217718045, 'average': 0.8029048695218264, 'sample_size': 798}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8027357778335252, 'median': 0.7911198383665954, 'mode': 0.9509556217718045, 'average': 0.8027357778335252, 'sample_size': 799}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8029410520370847, 'median': 0.7911941423292099, 'mode': 0.9509556217718045, 'average': 0.8029410520370847, 'sample_size': 800}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8031321990152092, 'median': 0.7912684462918246, 'mode': 0.9509556217718045, 'average': 0.8031321990152092, 'sample_size': 801}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8033343556349201, 'median': 0.7912684462918246, 'mode': 0.9509556217718045, 'average': 0.8033343556349201, 'sample_size': 802}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8035245367381331, 'median': 0.7912684462918246, 'mode': 0.9509556217718045, 'average': 0.8035245367381331, 'sample_size': 803}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.803725702498438, 'median': 0.7912684462918246, 'mode': 0.9509556217718045, 'average': 0.803725702498438, 'sample_size': 804}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8039149249568435, 'median': 0.7912684462918246, 'mode': 0.9509556217718045, 'average': 0.8039149249568435, 'sample_size': 805}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8040973575831649, 'median': 0.7912684462918246, 'mode': 0.9509556217718045, 'average': 0.8040973575831649, 'sample_size': 806}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.80430552601581, 'median': 0.7912684462918246, 'mode': 0.9509556217718045, 'average': 0.80430552601581, 'sample_size': 807}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8044870236590724, 'median': 0.7912684462918246, 'mode': 0.9509556217718045, 'average': 0.8044870236590724, 'sample_size': 808}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8046941957963638, 'median': 0.7912684462918246, 'mode': 0.9509556217718045, 'average': 0.8046941957963638, 'sample_size': 809}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8048747654580619, 'median': 0.7912684462918246, 'mode': 0.9509556217718045, 'average': 0.8048747654580619, 'sample_size': 810}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8050804124060604, 'median': 0.7912684462918246, 'mode': 0.9509556217718045, 'average': 0.8050804124060604, 'sample_size': 811}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8053204611592549, 'median': 0.7912684462918246, 'mode': 0.9509556217718045, 'average': 0.8053204611592549, 'sample_size': 812}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8055250539995077, 'median': 0.7912684462918246, 'mode': 0.9509556217718045, 'average': 0.8055250539995077, 'sample_size': 813}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8057639667095821, 'median': 0.7919447887621145, 'mode': 0.9509556217718045, 'average': 0.8057639667095821, 'sample_size': 814}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8059675133029259, 'median': 0.7926211312324043, 'mode': 0.9509556217718045, 'average': 0.8059675133029259, 'sample_size': 815}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8062052982130941, 'median': 0.792741761323311, 'mode': 0.9509556217718045, 'average': 0.8062052982130941, 'sample_size': 816}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8064078063429246, 'median': 0.7928623914142177, 'mode': 0.9509556217718045, 'average': 0.8064078063429246, 'sample_size': 817}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8066098193428538, 'median': 0.7928623914142177, 'mode': 0.9509556217718045, 'average': 0.8066098193428538, 'sample_size': 818}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8068459489895659, 'median': 0.7928623914142177, 'mode': 0.9509556217718045, 'average': 0.8068459489895659, 'sample_size': 819}}, {'prompt': 'What is today?', 'quant_scores': {'mean': 0.8070469349545599, 'median': 0.7928623914142177, 'mode': 0.9509556217718045, 'average': 0.8070469349545599, 'sample_size': 820}}]\n"
     ]
    }
   ],
   "source": [
    "#Test Cell\n",
    "my_prompt='What is today?'\n",
    "my_results3=process_prompt(my_prompt)\n",
    "print(my_prompt)\n",
    "print(my_results3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing has been completed and all functions are working as expected. This next cell block will test for version info of our modules.\n",
    "These shall be added to a requirement txt for a dockerfile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformers version: 4.36.2\n",
      "torch version: 2.1.2+cpu\n",
      "sklearn version: 1.3.2\n",
      "numpy version: 1.24.4\n",
      "scipy version: 1.10.1\n",
      "itertools is a built-in module, so it doesn't have a version.\n",
      "time is a built-in module, so it doesn't have a version.\n",
      "random is a built-in module, so it doesn't have a version.\n",
      "os is a built-in module, so it doesn't have a version.\n",
      "dotenv version: dotenv.main\n",
      "openai version: 1.6.1\n"
     ]
    }
   ],
   "source": [
    "# Import the required modules\n",
    "import transformers\n",
    "import torch\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import scipy\n",
    "import itertools\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Print the versions\n",
    "print(f\"transformers version: {transformers.__version__}\")\n",
    "print(f\"torch version: {torch.__version__}\")\n",
    "print(f\"sklearn version: {sklearn.__version__}\")\n",
    "print(f\"numpy version: {np.__version__}\")\n",
    "print(f\"scipy version: {scipy.__version__}\")\n",
    "print(f\"itertools is a built-in module, so it doesn't have a version.\")\n",
    "print(f\"time is a built-in module, so it doesn't have a version.\")\n",
    "print(f\"random is a built-in module, so it doesn't have a version.\")\n",
    "print(f\"os is a built-in module, so it doesn't have a version.\")\n",
    "print(f\"dotenv version: {load_dotenv.__module__}\")  # For dotenv, we use a different approach\n",
    "\n",
    "# The OpenAI module version might need a different approach since it's often installed via pip\n",
    "# and doesn't always have a __version__ attribute. We use pkg_resources to get the version.\n",
    "try:\n",
    "    import pkg_resources\n",
    "    openai_version = pkg_resources.get_distribution(\"openai\").version\n",
    "    print(f\"openai version: {openai_version}\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not determine openai version: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
